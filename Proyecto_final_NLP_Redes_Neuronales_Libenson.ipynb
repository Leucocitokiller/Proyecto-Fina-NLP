{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5AH8MLYjfwgp",
        "VMtpSPyriRkl",
        "ubaprtVKf88y",
        "Eagv-jaJgM_z",
        "D12fghhagRjE",
        "SDKeqnp-gqyc",
        "39XV91NgkM9r",
        "R79sGteNkpVT",
        "_NKoVBUUkw0D",
        "1KM1qtISk-6T",
        "ZhnBUrQTl_BT",
        "ZBXkyZRzmSdj",
        "9bW_hSCRm02p",
        "GNDNz9V5m_EU",
        "GVqmZ6rRoDTd",
        "VCXSZ4glokBF",
        "njpl5RHiosuU",
        "3h4HlXQzpWl0",
        "lZQPvZfZszkC",
        "qD43WO8o5LaU",
        "AvQezV_qx8g4",
        "ELvckxoswXK5"
      ],
      "authorship_tag": "ABX9TyNE0nsR/nj9g102/PYhdIS6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leucocitokiller/Proyecto-Fina-NLP/blob/main/Proyecto_final_NLP_Redes_Neuronales_Libenson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importación de Librerías."
      ],
      "metadata": {
        "id": "5AH8MLYjfwgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "#-----librerias para trabajar PLN\n",
        "!python -m spacy download es_core_news_md\n",
        "import spacy\n",
        "import es_core_news_md\n",
        "#es_core_news_md Medium (modelo mediano):\n",
        "#Es más pesado y más lento que el sm, pero mucho más preciso. Tiene vectores de palabras, entiende mejor el significado de las palabras.\n",
        "\n",
        "#-----instalación d librerias para análisis de sentimientos.\n",
        "!pip install spacy spacy-transformers\n",
        "!pip install pysentimiento\n",
        "from pysentimiento import create_analyzer\n",
        "\n",
        "#----librerias para normalización de textos\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#----librerias para graficar y wordcloud.\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#----librerías para trabajar con TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#----libreria para trabajar con BoW.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#----librerias para Machine learning\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "64jaT-pwfyzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento de la Fuente de Datos."
      ],
      "metadata": {
        "id": "VMtpSPyriRkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexión con la fuente de datos.\n"
      ],
      "metadata": {
        "id": "ubaprtVKf88y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario con las fuentes y sus URLs\n",
        "filepath_dict = {\n",
        "    'yelp': 'https://raw.githubusercontent.com/Leucocitokiller/Proyecto-Fina-NLP/main/yelp_comentarios.csv',\n",
        "    'amazon': 'https://raw.githubusercontent.com/Leucocitokiller/Proyecto-Fina-NLP/main/amazon_cells_comentarios.csv'\n",
        "\n",
        "}\n",
        "\n",
        "df_list = []\n",
        "for source, filepath in filepath_dict.items():\n",
        "    df = pd.read_csv(filepath, names=['Comentario', 'Valor'], sep=';', encoding='latin-1')\n",
        "    df['Origen'] = source  # Add another column filled with the source name\n",
        "    df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list)\n",
        "df.head(1100)"
      ],
      "metadata": {
        "id": "QA3En5EYgAtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eMRxpuFsht3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalización de la Fuente de datos.\n"
      ],
      "metadata": {
        "id": "Eagv-jaJgM_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eliminación de signos de puntuación."
      ],
      "metadata": {
        "id": "D12fghhagRjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de función para eliminar los signos de puntuación utilizando re, pero considerando no borrar las vocales con acento.\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Normaliza el texto a NFKD para separar letras y sus tildes\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    # Elimina los caracteres diacríticos (como las tildes)\n",
        "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
        "    # Elimina todo lo que no sea letras, números o espacios\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Aplicar la función a la columna 'review_lower'\n",
        "df['Comentarios'] = df['Comentario'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "TlTn8VuygQxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ez4O1zkbhB2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reducir a minúsculas el texto."
      ],
      "metadata": {
        "id": "SDKeqnp-gqyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column 'Comentarios_lower' with lowercase values from 'Comentario'\n",
        "df['Comentarios_lower'] = df['Comentarios'].str.lower()"
      ],
      "metadata": {
        "id": "ExcMpIx7gw-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_O0hOspchMl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convertir a número la columna Valor para su postprocesamiento."
      ],
      "metadata": {
        "id": "jk6_6oiZg5Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos la columna rating a valor numérico\n",
        "df['Valor'] = pd.to_numeric(df['Valor'], errors='coerce')"
      ],
      "metadata": {
        "id": "a_urHIsIg7Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Valor']"
      ],
      "metadata": {
        "id": "yUwGYj_jhIud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP"
      ],
      "metadata": {
        "id": "39XV91NgkM9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Procesamiento."
      ],
      "metadata": {
        "id": "R79sGteNkpVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generación del objeto de SPacy para utilizar en el procesamiento del texto en español."
      ],
      "metadata": {
        "id": "_NKoVBUUkw0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = es_core_news_md.load()"
      ],
      "metadata": {
        "id": "aiW_XvTOkm2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convertir texto a minúsculas y Tokenización."
      ],
      "metadata": {
        "id": "1KM1qtISk-6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Comentarios_tokenizados'] = df['Comentarios_lower'].apply(lambda text: nlp(text))\n",
        "df[['Comentarios_lower','Comentarios_tokenizados']].head()"
      ],
      "metadata": {
        "id": "uVF3ar5olBDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remoción de StopWords"
      ],
      "metadata": {
        "id": "ZhnBUrQTl_BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de palabras que NO queremos eliminar (tienen carga emocional)\n",
        "palabras_sentimiento = {\n",
        "    # Positivas\n",
        "    \"bueno\", \"buena\",\"si\",\"buenísimo\", \"excelentes\", \"excelente\", \"genial\", \"maravilloso\", \"maravilla\", \"fantástico\", \"fabuloso\", \"increíble\",\n",
        "    \"perfecto\", \"perfecta\", \"agradable\", \"satisfecho\", \"satisfecha\", \"contento\", \"contenta\", \"encantado\", \"encantada\",\n",
        "    \"amable\", \"simpático\", \"simpática\", \"rápido\", \"rápida\", \"cómodo\", \"cómoda\", \"eficaz\", \"eficiente\", \"fácil\",\n",
        "    \"recomendable\", \"ideal\", \"espectacular\", \"feliz\", \"brillante\", \"cumplió\", \"cumple\", \"funciona\", \"funciona bien\",\n",
        "    \"inmejorable\", \"confiable\", \"duradero\", \"cumplidor\", \"seguro\", \"preciso\", \"elegante\", \"atento\", \"responsable\",\n",
        "    \"acertado\", \"destacado\", \"excepcional\", \"impecable\", \"sensacional\", \"útil\", \"accesible\", \"económico\", \"funcional\",\n",
        "    \"intuitivo\", \"conveniente\", \"hermoso\", \"linda\", \"precioso\", \"excelente calidad\", \"vale la pena\",\n",
        "\n",
        "    # Negativas\n",
        "    \"malo\",\"no\", \"mala\", \"mal\", \"pésimo\", \"pésima\",\"nunca\", \"horrible\", \"fatal\", \"insoportable\", \"lento\", \"lenta\", \"incómodo\", \"incómoda\",\n",
        "    \"decepcionante\", \"decepcionado\", \"decepcionada\", \"sucio\", \"sucia\", \"caro\", \"cara\", \"inútil\", \"deficiente\", \"desagradable\",\n",
        "    \"complicado\", \"problemático\", \"estafa\", \"engañado\", \"engañada\", \"roto\", \"rota\", \"desastroso\", \"error\", \"errores\",\n",
        "    \"retraso\", \"tardanza\", \"frágil\", \"inestable\", \"poco fiable\", \"nunca más\", \"no volveré\", \"no recomiendo\", \"no sirve\",\n",
        "    \"no funciona\", \"arruinado\", \"falló\", \"fallando\", \"demora\", \"pésima atención\", \"servicio malo\", \"mala calidad\", \"molesto\",\n",
        "    \"defecto\", \"problemas\", \"fallas\", \"sin sentido\", \"basura\", \"pérdida de dinero\", \"decepción\"\n",
        "}\n",
        "\n",
        "# Actualizamos spaCy para que NO considere esas palabras como stopwords\n",
        "for palabra in palabras_sentimiento:\n",
        "    lex = nlp.vocab[palabra]\n",
        "    lex.is_stop = False\n",
        "\n",
        "\n",
        "\n",
        "def parse_and_remove_stopwords(doc):\n",
        "    \"\"\"\n",
        "    Remueve las stopwords de un objeto spaCy Doc.\n",
        "    \"\"\"\n",
        "    # Filtrar stopwords y obtener los tokens como texto\n",
        "    tokens_filtrados = [token.text for token in doc if not token.is_stop]\n",
        "    return tokens_filtrados\n",
        "\n",
        "# Aplicar la función al DataFrame\n",
        "df['Comentarios_sin_StopWords'] = df['Comentarios_tokenizados'].apply(parse_and_remove_stopwords)\n",
        "\n",
        "df[['Comentarios_tokenizados','Comentarios_sin_StopWords']].head()"
      ],
      "metadata": {
        "id": "2_cr__EqmG4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lematizado."
      ],
      "metadata": {
        "id": "ZBXkyZRzmSdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lematizar_sin_stopwords(doc):\n",
        "    \"\"\"\n",
        "    Devuelve una lista de lemas excluyendo las stopwords.\n",
        "\n",
        "    Parámetro:\n",
        "    - doc: objeto spaCy Doc\n",
        "\n",
        "    Retorna:\n",
        "    - Lista de lemas (str) sin stopwords\n",
        "    \"\"\"\n",
        "    return [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
        "\n",
        "# Aplicar la función y guardar el resultado en una nueva columna\n",
        "df['Comentarios_lema'] = df['Comentarios_tokenizados'].apply(lematizar_sin_stopwords)\n",
        "\n",
        "df[['Comentarios_tokenizados','Comentarios_lema']].head(20)"
      ],
      "metadata": {
        "id": "DsRRS29ImVnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesamiento"
      ],
      "metadata": {
        "id": "9bW_hSCRm02p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conteo de Palabras mas comunes."
      ],
      "metadata": {
        "id": "GNDNz9V5m_EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graficar_palabras_comunes(df, origen, top_n=10):\n",
        "    # Filtrar y aplanar los lemas\n",
        "    lemas = [lema for lemas in df[df['Origen'] == origen]['Comentarios_lema'] for lema in lemas]\n",
        "    conteo = Counter(lemas).most_common(top_n)\n",
        "\n",
        "    # Separar palabras y frecuencias\n",
        "    palabras, frecuencias = zip(*conteo)\n",
        "\n",
        "    # Crear gráfico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(palabras, frecuencias, color='skyblue')\n",
        "    plt.xlabel('Frecuencia')\n",
        "    plt.title(f'Top {top_n} Palabras Más Comunes - {origen.capitalize()}')\n",
        "    plt.gca().invert_yaxis()  # Poner la palabra más común arriba\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Graficar para Yelp\n",
        "graficar_palabras_comunes(df, 'yelp')\n",
        "\n",
        "# Graficar para Amazon\n",
        "graficar_palabras_comunes(df, 'amazon')"
      ],
      "metadata": {
        "id": "cHPKUNjjoJQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conteo de bigramas más comunes."
      ],
      "metadata": {
        "id": "GVqmZ6rRoDTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from itertools import tee\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generar_bigramas(lista):\n",
        "    \"\"\"Devuelve bigramas como tuplas a partir de una lista de palabras\"\"\"\n",
        "    a, b = tee(lista)\n",
        "    next(b, None)\n",
        "    return list(zip(a, b))\n",
        "\n",
        "def graficar_bigramas_comunes(df, origen, top_n=10):\n",
        "    # Filtrar solo los comentarios del origen y generar bigramas\n",
        "    bigramas = [\n",
        "        bigrama\n",
        "        for lemas in df[df['Origen'] == origen]['Comentarios_lema']\n",
        "        for bigrama in generar_bigramas(lemas)\n",
        "    ]\n",
        "\n",
        "    conteo = Counter(bigramas).most_common(top_n)\n",
        "\n",
        "    # Convertir tuplas de bigramas a string para graficar\n",
        "    etiquetas = [' '.join(b) for b, _ in conteo]\n",
        "    frecuencias = [f for _, f in conteo]\n",
        "\n",
        "    # Crear gráfico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(etiquetas, frecuencias, color='mediumseagreen')\n",
        "    plt.xlabel('Frecuencia')\n",
        "    plt.title(f'Top {top_n} Bigramas Más Comunes - {origen.capitalize()}')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejemplo de uso\n",
        "graficar_bigramas_comunes(df, 'yelp')\n",
        "graficar_bigramas_comunes(df, 'amazon')\n"
      ],
      "metadata": {
        "id": "_B3v3nOknL2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WordClouds"
      ],
      "metadata": {
        "id": "tn6x4GaEoYRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud Yelp."
      ],
      "metadata": {
        "id": "VCXSZ4glokBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el DataFrame\n",
        "df_yelp = df[df['Origen'] == 'yelp']\n",
        "\n",
        "# Unir todos los lemas en un solo string (comentarios lematizados ya están en listas)\n",
        "texto_yelp = ' '.join([' '.join(lemas) for lemas in df_yelp['Comentarios_lema']])\n",
        "\n",
        "# Crear la nube de palabras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto_yelp)\n",
        "\n",
        "# Mostrar la nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nube de Palabras - Comentarios de Yelp\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UXGDKZCaocLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud Amazon."
      ],
      "metadata": {
        "id": "njpl5RHiosuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el DataFrame\n",
        "df_amazon = df[df['Origen'] == 'amazon']\n",
        "\n",
        "# Unir todos los lemas en un solo string (comentarios lematizados ya están en listas)\n",
        "texto_amazon = ' '.join([' '.join(lemas) for lemas in df_amazon['Comentarios_lema']])\n",
        "\n",
        "# Crear la nube de palabras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto_amazon)\n",
        "\n",
        "# Mostrar la nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nube de Palabras - Comentarios de Yelp\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PHfxMdccou0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud + Bigramas."
      ],
      "metadata": {
        "id": "_ryxqKXUo6Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_bigramas_spacy(df, origen, top_n=50):\n",
        "    \"\"\"\n",
        "    Genera bigramas usando spaCy a partir de la columna 'Comentarios_Lema', sin stopwords.\n",
        "    Luego genera una nube de palabras.\n",
        "    \"\"\"\n",
        "    # Filtrar los comentarios por 'origen' (por ejemplo, 'yelp' o 'amazon')\n",
        "    comentarios = df[df['Origen'] == origen]['Comentarios_sin_StopWords']\n",
        "\n",
        "    # Generar bigramas\n",
        "    bigramas = []\n",
        "    for comentario in comentarios:\n",
        "        # Crear un Doc de spaCy a partir de la lista de lemas (de la columna 'Comentarios_Lema')\n",
        "        doc = nlp(' '.join(comentario))  # Unimos la lista de lemas y lo procesamos con spaCy\n",
        "        # Extraer bigramas\n",
        "        for i in range(len(doc) - 1):\n",
        "            if not doc[i].is_stop and not doc[i+1].is_stop:  # Asegurarse de que no sean stopwords\n",
        "                bigramas.append((doc[i].lemma_, doc[i+1].lemma_))\n",
        "\n",
        "    # Contar los bigramas más comunes\n",
        "    conteo_bigramas = Counter(bigramas).most_common(top_n)\n",
        "\n",
        "    # Convertir los bigramas a formato texto \"palabra1 palabra2\"\n",
        "    bigramas_texto = {' '.join(bigrama): freq for bigrama, freq in conteo_bigramas}\n",
        "\n",
        "    # Generar la nube de palabras de los bigramas\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(bigramas_texto)\n",
        "\n",
        "    # Mostrar la nube\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Word Cloud de Bigramas - {origen.capitalize()}\")\n",
        "    plt.show()\n",
        "\n",
        "# Generar la nube de bigramas para Yelp y Amazon\n",
        "generar_bigramas_spacy(df, 'yelp')\n",
        "generar_bigramas_spacy(df, 'amazon')"
      ],
      "metadata": {
        "id": "qW644mkPo8qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🚀 Análisis de sentimiento en español con pysentimiento"
      ],
      "metadata": {
        "id": "3h4HlXQzpWl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear analizador de sentimientos\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "\n",
        "# Aplicar a una columna de texto\n",
        "df['Sentimiento'] = df['Comentario'].apply(lambda x: analyzer.predict(x).output)\n",
        "# Sentimiento solo guarda lo predicho (POS, NEU o NEG)\n",
        "\n",
        "df['Probabilidad'] = df['Comentario'].apply(lambda x: analyzer.predict(x).probas)\n",
        "#Ese diccionario contiene la probabilidad de cada clase: positivo, neutro, negativo Ejemplo: {'POS': 0.84, 'NEU': 0.10, 'NEG': 0.06}."
      ],
      "metadata": {
        "id": "r5feGF2Gpias"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 📊  Gráfico de barras de frecuencia de sentimientos"
      ],
      "metadata": {
        "id": "lZQPvZfZszkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, x='Sentimiento', order=['POS', 'NEU', 'NEG'], palette='pastel')\n",
        "plt.title('Distribución de Sentimientos totales entre Yelp y Amazon')\n",
        "plt.xlabel('Sentimiento')\n",
        "plt.ylabel('Cantidad de Comentarios')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ddaD7cous3SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribución de los sentimientos."
      ],
      "metadata": {
        "id": "NyE94c4JtDWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentimiento'].value_counts().plot.pie(\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    labels=['Positivo', 'Neutro', 'Negativo'],\n",
        "    colors=['lightgreen', 'lightblue', 'salmon']\n",
        ")\n",
        "plt.title('Distribución porcentual de Sentimientos')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dI2qGwfVs837"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Análisis de Confianza para filtrar comentarios con baja certeza"
      ],
      "metadata": {
        "id": "N9Ehqc_htP8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Máxima probabilidad (nivel de certeza del modelo)\n",
        "df['Confianza'] = df['Probabilidad'].apply(lambda x: max(x.values()))  # En este caso, de la lista {'POS': 0.84, 'NEU': 0.10, 'NEG': 0.06} sólo guarda 0.84 que es el valor mayor\n",
        "\n",
        "# Filtrar comentarios cuya confianza sea menor a 0.6\n",
        "comentarios_baja_confianza = df[df['Confianza'] < 0.6]\n",
        "comentarios_alta_confianza = df[df['Confianza'] >= 0.6]\n",
        "# Ver los primeros resultados\n",
        "#comentarios_baja_confianza[['Comentarios', 'Sentimiento', 'Confianza']]"
      ],
      "metadata": {
        "id": "cp_TPbgYtUPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribución de los comentarios filtrados."
      ],
      "metadata": {
        "id": "Np0Wbkh-t9ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Confianza'] >= 0.6]['Sentimiento'].value_counts().plot.pie(\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    labels=['Positivo', 'Neutro', 'Negativo'],\n",
        "    colors=['lightgreen', 'lightblue', 'salmon']\n",
        ")\n",
        "plt.title('Distribución porcentual de Sentimientos con alta confianza')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DKGk25nltsFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribución de la Confianza de los comentarios."
      ],
      "metadata": {
        "id": "8UwgeOBbuhWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data=df, x='Confianza', bins=20, kde=True, color='skyblue')\n",
        "plt.axvline(0.6, color='red', linestyle='--', label='Umbral 0.6')\n",
        "plt.title('Distribución de Confianza del Sentimiento')\n",
        "plt.xlabel('Confianza')\n",
        "plt.ylabel('Cantidad de Comentarios')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W1mX2p80uabR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pruebas de Modelos de Machine Learning."
      ],
      "metadata": {
        "id": "vk7QPjtIv4rZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### División de datos de entrenamiento y prueba."
      ],
      "metadata": {
        "id": "qD43WO8o5LaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['Comentario'], df['Valor'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jkK0y7oy5Z_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística."
      ],
      "metadata": {
        "id": "2189jWXqwNhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando TF-IFD."
      ],
      "metadata": {
        "id": "JBBoS9QowA6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (Term Frequency - Inverse Document Frequency) es una técnica de procesamiento de texto utilizada para evaluar la importancia de una palabra dentro de un conjunto de documentos. Se basa en dos conceptos:\n",
        "\n",
        "TF (Frecuencia de Término): Mide cuántas veces aparece un término en un documento específico, comparado con el número total de términos en ese documento. Esto ayuda a capturar cuán relevante es una palabra dentro de un documento en particular.\n",
        "\n",
        "IDF (Frecuencia Inversa de Documentos): Mide la importancia de una palabra dentro de un conjunto de documentos. Si una palabra aparece en muchos documentos, tiene menos valor. La fórmula es:\n",
        "\n",
        "Esto ayuda a reducir el peso de las palabras que aparecen frecuentemente en todos los documentos (como \"el\", \"y\", \"de\"), ya que no agregan mucha información.\n",
        "\n",
        "Así, la importancia de un término en un documento depende tanto de su frecuencia en ese documento como de cuán común es en todo el conjunto de documentos."
      ],
      "metadata": {
        "id": "Z5Qu0o3RwyoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cálculo de TF-IDF con TfidVetorizer."
      ],
      "metadata": {
        "id": "AvQezV_qx8g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # TFIDF espera trabajar con strings y  no listas, por lo que se procede a crear una nueva columna con los datos tokenizados en formato str.\n",
        "df['Comentarios_sin_StopWords_str'] = df['Comentarios_sin_StopWords'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Crear el vectorizador\n",
        "tfidfvectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
        "#inlcuyo bigramas y trigramas para que le de contexto a los comentarios. Esto me permite ver un \"No conforme\" y no solamente le \"No\" y el \"Conforme\" por separado.\n",
        "\n",
        "# Ajustar y transformar\n",
        "tfidf_matrix = tfidfvectorizer.fit_transform(df['Comentarios_sin_StopWords_str'])\n",
        "\n",
        "# Obtener los términos\n",
        "features = tfidfvectorizer.get_feature_names_out()\n",
        "\n",
        "# Convertir la matriz a DataFrame\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=features)\n",
        "\n",
        "# Sumar TF-IDF por columna\n",
        "tfidf_scores = df_tfidf.sum().sort_values(ascending=False)\n",
        "\n",
        "# Mostrar top 10\n",
        "print(\"🔝 Top 10 n-gramas por score TF-IDF:\")\n",
        "print(tfidf_scores.head(10).round(3))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yOA1KulbyJG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame auxiliar con el tipo de n-grama\n",
        "df_scores = pd.DataFrame({\n",
        "    'ngram': tfidf_scores.index,\n",
        "    'score': tfidf_scores.values,\n",
        "    'tipo': tfidf_scores.index.to_series().apply(lambda x: f'{len(x.split())}-grama')\n",
        "})\n",
        "\n",
        "# Ver los 5 más importantes por tipo\n",
        "top_n = 5\n",
        "for tipo in ['1-grama', '2-grama', '3-grama']:\n",
        "    print(f\"\\n🔝 Top {top_n} {tipo}s:\")\n",
        "    print(df_scores[df_scores['tipo'] == tipo].head(top_n).to_string(index=False))"
      ],
      "metadata": {
        "id": "8TncVynMzZlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b4VhVp3p41Q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ajuste de datos de Entrenamiento."
      ],
      "metadata": {
        "id": "jGzhxUtp6DAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar y transformar los datos de entrenamiento\n",
        "X_train_tfidf = tfidfvectorizer.fit_transform(X_train)\n",
        "# Transformar los datos de prueba\n",
        "X_test_tfidf = tfidfvectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "C9X3Y3tX6JQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generación y prueba de modelo Regresión Logística."
      ],
      "metadata": {
        "id": "4zXnyKl47GSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un modelo de regresión logística\n",
        "# Abajo tenés un código con los parámetros expresados de forma que puedas ir modificandolos\n",
        "model_log_reg = LogisticRegression() #Instanciamos el modelo\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_log_reg.fit(X_train_tfidf, y_train) # Fiteamos, es decir, el modelo aprende a partir de los datos de entrenamiento\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "y_pred_log_reg = model_log_reg.predict(X_test_tfidf) # Predecir"
      ],
      "metadata": {
        "id": "lmGzeGnU7NlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluación del Modelo."
      ],
      "metadata": {
        "id": "BKMGMFHX8OKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusión."
      ],
      "metadata": {
        "id": "i8zfSea79_Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Matriz de confusión\n",
        "\n",
        "# La Matriz de Confusión es útil para Muestra los aciertos y errores del modelo organizados por clase.\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_log_reg)\n",
        "labels = ['Negativo', 'Positivo']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SZu-1myh8k3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curva ROC AUC."
      ],
      "metadata": {
        "id": "YAkrMHlM-DEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Curva ROC\n",
        "# ROC AUC SCORE evalúa qué tan bien el modelo separa las clases.\n",
        "fpr, tpr, _ = roc_curve(y_test, model_log_reg.decision_function(X_test_tfidf))\n",
        "roc_auc = roc_auc_score(y_test, model_log_reg.decision_function(X_test_tfidf))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Área bajo la curva ROC AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o6Iu7ehz9ZCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas de Predicción."
      ],
      "metadata": {
        "id": "Tzf7JNqq-FnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Métricas\n",
        "# Accuracy:Para medir qué tan bien predice el modelo en datos nuevos (exactitud).\n",
        "# Accuracy mide el porcentaje total de predicciones correctas sobre el total de casos.\n",
        "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
        "# Precision: Para medir el costo de un falso positivo es alto (por ejemplo, recomendar una película mala como buena).\n",
        "# Precision mide qué proporción de las predicciones positivas hechas por el modelo son realmente positivas.\n",
        "precision = precision_score(y_test, y_pred_log_reg)\n",
        "# Recall: Para medir cuántos de los casos positivos reales fueron capturados por el modelo.\n",
        "recall = recall_score(y_test, y_pred_log_reg)\n",
        "# f1 Score: Para medir el promedio armónico entre precisión y recall. Un buen balance si ambas cosas son importantes.\n",
        "f1 = f1_score(y_test, y_pred_log_reg)\n",
        "\n",
        "print(\"Métricas de desempeño del modelo:\")\n",
        "print(f\"Accuracy : {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall   : {recall:.2f}\")\n",
        "print(f\"F1 Score : {f1:.2f}\")"
      ],
      "metadata": {
        "id": "yhq9A09B9Y2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación Cruzada."
      ],
      "metadata": {
        "id": "YhVd_UpcIthW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline que junta vectorizador y modelo\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=5000),\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "# Validación cruzada con 5 particiones (k-fold = 5)\n",
        "scores = cross_val_score(pipeline, df['Comentario'], df['Valor'], cv=5, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(f\"Precisión media con validación cruzada: {scores.mean():.3f}\")\n",
        "print(f\"Desviación estándar: {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "I1TpkwSyI8OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualización de palabras asociadas a reseñas positivas y negativas."
      ],
      "metadata": {
        "id": "voZXIBS9QDz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos las palabras del vocabulario\n",
        "palabras = tfidfvectorizer.get_feature_names_out()\n",
        "\n",
        "# Coeficientes del modelo (uno por palabra)\n",
        "coeficientes = model_log_reg.coef_[0]\n",
        "\n",
        "# Creamos un DataFrame para visualizarlo\n",
        "df_coef = pd.DataFrame({'palabra': palabras, 'coeficiente': coeficientes})\n",
        "\n",
        "# Ordenamos por importancia\n",
        "df_coef = df_coef.sort_values(by='coeficiente', ascending=False)\n",
        "\n",
        "# En la primera columna veremos el número \"índice\" de cada palabra según el órden en que fueron procesadas en el modelo.\n",
        "\n",
        "# Mostramos las 10 palabras más asociadas a valoración positiva y negativa\n",
        "print(\"🔼 Palabras más asociadas a reseñas positivas:\")\n",
        "print(df_coef.head(10))\n",
        "\n",
        "print(\"\\n🔽 Palabras más asociadas a reseñas negativas:\")\n",
        "print(df_coef.tail(10))"
      ],
      "metadata": {
        "id": "2bJEOJTHQKb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficar las 10 palabras más positivas y más negativas"
      ],
      "metadata": {
        "id": "6inidvU-R88J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colores pastel suaves (más apagados)\n",
        "color_positivas = '#388e3c'  # verde claro apagado\n",
        "color_negativas = '#e65100'  # rojo claro apagado\n",
        "\n",
        "# Top 10 positivas y negativas\n",
        "top_positivas = df_coef.head(10)\n",
        "top_negativas = df_coef.tail(10).sort_values(by='coeficiente')\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Gráfico de palabras positivas\n",
        "bars1 = ax[0].barh(top_positivas['palabra'], top_positivas['coeficiente'], color=color_positivas)\n",
        "ax[0].set_title('🔼 Palabras asociadas a reseñas positivas', fontsize=14)\n",
        "ax[0].invert_yaxis()\n",
        "ax[0].set_xlabel('Coeficiente', fontsize=12)\n",
        "\n",
        "# Agregar valores al final de las barras (positivas)\n",
        "for bar in bars1:\n",
        "    width = bar.get_width()\n",
        "    ax[0].text(width + 0.01, bar.get_y() + bar.get_height() / 2,\n",
        "               f'{width:.2f}', va='center', fontsize=10)\n",
        "\n",
        "# Gráfico de palabras negativas\n",
        "bars2 = ax[1].barh(top_negativas['palabra'], top_negativas['coeficiente'], color=color_negativas)\n",
        "ax[1].set_title('🔽 Palabras asociadas a reseñas negativas', fontsize=14)\n",
        "ax[1].invert_yaxis()\n",
        "ax[1].set_xlabel('Coeficiente', fontsize=12)\n",
        "\n",
        "# Agregar valores al final de las barras (negativas)\n",
        "for bar in bars2:\n",
        "    width = bar.get_width()\n",
        "    ax[1].text(width - 0.01, bar.get_y() + bar.get_height() / 2,\n",
        "               f'{width:.2f}', va='center', ha='right', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VnNJCbVbRLMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar bigramas y trigramas\n",
        "# Cambiar 'ngrama' a 'palabra' para acceder a la columna correcta\n",
        "df_bi_tri = df_coef[df_coef['palabra'].str.count(' ') >= 2]\n",
        "\n",
        "top_pos_bi_tri = df_bi_tri.sort_values('coeficiente', ascending=False).head(10)\n",
        "top_neg_bi_tri = df_bi_tri.sort_values('coeficiente', ascending=True).head(10)\n",
        "\n",
        "color_positivas = '#388e3c'  # verde oscuro\n",
        "color_negativas = '#e65100'  # naranja oscuro\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
        "\n",
        "axes[0].barh(top_pos_bi_tri['palabra'], top_pos_bi_tri['coeficiente'], color=color_positivas) # Cambiar 'ngrama' a 'palabra'\n",
        "axes[0].invert_yaxis()\n",
        "axes[0].set_title('🔼 Bigrams y Trigrams positivos')\n",
        "axes[0].set_xlabel('Coeficiente')\n",
        "\n",
        "axes[1].barh(top_neg_bi_tri['palabra'], top_neg_bi_tri['coeficiente'], color=color_negativas) # Cambiar 'ngrama' a 'palabra'\n",
        "axes[1].invert_yaxis()\n",
        "axes[1].set_title('🔽 Bigrams y Trigrams negativos')\n",
        "axes[1].set_xlabel('Coeficiente')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VgoYFK0eTcBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 ¿Qué muestran los gráficos?\n",
        "Las palabras con coeficientes positivos son las que más contribuyen a que el modelo prediga una reseña positiva.\n",
        "\n",
        "Las palabras con coeficientes negativos son las que más empujan al modelo hacia una predicción negativa."
      ],
      "metadata": {
        "id": "11CjMM0lR28T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prueba del modelo."
      ],
      "metadata": {
        "id": "bbw6-1oWJYA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nueva_reseña = \"no lo recominedo\"  # Reemplaza con la reseña que deseas probar\n",
        "nueva_reseña_tfidf = tfidfvectorizer.transform([nueva_reseña])\n",
        "prediccion = model_log_reg.predict(nueva_reseña_tfidf)\n",
        "# Obtener la probabilidad de la predicción\n",
        "probabilidadpositiva = model_log_reg.predict_proba(nueva_reseña_tfidf)\n",
        "\n",
        "# Obtener la probabilidad en la clase predicha (0 o 1)\n",
        "probabilidad = probabilidadpositiva[0][1]  # Probabilidad de la clase \"positivo\"\n",
        "\n",
        "print(f\"Se predice que la crítica es de caracter {prediccion[0]}\")\n",
        "print(f\" con una probabilidad de que sea positiva de {probabilidad:.2f}\")"
      ],
      "metadata": {
        "id": "W8rk_rn_JdGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando Bag of Words."
      ],
      "metadata": {
        "id": "6nA1NdjV-tYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW convierte un conjunto de documentos en una matriz de ocurrencias de palabras. A diferencia de TF-IDF, que pondera las palabras según su frecuencia e importancia en relación con todo el corpus, BoW solo cuenta cuántas veces aparece una palabra en un documento sin considerar la frecuencia global de la palabra."
      ],
      "metadata": {
        "id": "4N3SqoNl-9SG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ajuste de datos de entrenamiento para BoW."
      ],
      "metadata": {
        "id": "9O22cegICxIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciamos el vectorizador BoW\n",
        "vectorizer_bow = CountVectorizer()\n",
        "\n",
        "# Aplicamos el vectorizador a los comentarios lematizados (ahora en formato string)\n",
        "vector_bow = vectorizer_bow.fit_transform(df['Comentarios_sin_StopWords_str'])\n",
        "\n",
        "# Convertimos la matriz de características en un DataFrame para visualizar\n",
        "bow_df = pd.DataFrame(vector_bow.toarray(), columns=vectorizer_bow.get_feature_names_out())\n",
        "\n",
        "# Obtener los nombres de las características (palabras)\n",
        "features_bow = vectorizer_bow.get_feature_names_out()\n",
        "\n",
        "\n",
        "# Crear un DataFrame con las frecuencias de las palabras\n",
        "df_bow = pd.DataFrame(vector_bow.toarray(), columns=features_bow)"
      ],
      "metadata": {
        "id": "puoPyVHMDFOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar y transformar los datos de entrenamiento\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
        "# Transformar los datos de prueba\n",
        "X_test_bow  = X_test_bow  = vectorizer_bow.transform(X_test)"
      ],
      "metadata": {
        "id": "KuBThnFkC0eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generación y prueba del Modelo con BoW."
      ],
      "metadata": {
        "id": "U-LmgSjwHBdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un modelo de regresión logística\n",
        "# Abajo tenés un código con los parámetros expresados de forma que puedas ir modificandolos\n",
        "model_log_reg_Bow = LogisticRegression() #Instanciamos el modelo\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_log_reg_Bow.fit(X_train_bow, y_train) # Fiteamos, es decir, el modelo aprende a partir de los datos de entrenamiento\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "y_pred_log_reg_Bow = model_log_reg_Bow.predict(X_test_bow) # Predecir"
      ],
      "metadata": {
        "id": "qGBcMOnvHAle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluación del Modelo.\n"
      ],
      "metadata": {
        "id": "PSo23e2IHX2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusión."
      ],
      "metadata": {
        "id": "LxPQYjq3HhL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Matriz de confusión\n",
        "\n",
        "# La Matriz de Confusión es útil para Muestra los aciertos y errores del modelo organizados por clase.\n",
        "\n",
        "cm1 = confusion_matrix(y_test, y_pred_log_reg_Bow)\n",
        "labels = ['Negativo', 'Positivo']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusiónc con BoW')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E9PBCupjHi8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curva ROC AUC."
      ],
      "metadata": {
        "id": "tlGSMfUAH1D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Curva ROC\n",
        "# ROC AUC SCORE evalúa qué tan bien el modelo separa las clases.\n",
        "fpr1, tpr1, _ = roc_curve(y_test, model_log_reg_Bow.decision_function(X_test_bow))\n",
        "roc_auc1 = roc_auc_score(y_test, model_log_reg_Bow.decision_function(X_test_bow))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr1, tpr1, color='darkorange', lw=2, label=f'Área bajo la curva ROC AUC = {roc_auc1:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HONvbjo4HzuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas de Predicción."
      ],
      "metadata": {
        "id": "vW0kWKhaIHmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Métricas\n",
        "# Accuracy:Para medir qué tan bien predice el modelo en datos nuevos (exactitud).\n",
        "# Accuracy mide el porcentaje total de predicciones correctas sobre el total de casos.\n",
        "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
        "# Precision: Para medir el costo de un falso positivo es alto (por ejemplo, recomendar una película mala como buena).\n",
        "# Precision mide qué proporción de las predicciones positivas hechas por el modelo son realmente positivas.\n",
        "precision = precision_score(y_test, y_pred_log_reg)\n",
        "# Recall: Para medir cuántos de los casos positivos reales fueron capturados por el modelo.\n",
        "recall = recall_score(y_test, y_pred_log_reg)\n",
        "# f1 Score: Para medir el promedio armónico entre precisión y recall. Un buen balance si ambas cosas son importantes.\n",
        "f1 = f1_score(y_test, y_pred_log_reg)\n",
        "\n",
        "print(\"Métricas de desempeño del modelo:\")\n",
        "print(f\"Accuracy : {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall   : {recall:.2f}\")\n",
        "print(f\"F1 Score : {f1:.2f}\")"
      ],
      "metadata": {
        "id": "I2xeBzIoIL4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación Cruzada con BoW."
      ],
      "metadata": {
        "id": "NFXHSA1wO2U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline con Bag of Words y Regresión Logística\n",
        "pipeline1 = make_pipeline(\n",
        "    CountVectorizer(max_features=5000),  # Bag of Words\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "# Validación cruzada con 5 particiones\n",
        "scores = cross_val_score(pipeline1, df['Comentario'], df['Valor'], cv=5, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(f\"Precisión media con validación cruzada (BoW): {scores.mean():.3f}\")\n",
        "print(f\"Desviación estándar: {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "vjenYlA_O4eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neuronales."
      ],
      "metadata": {
        "id": "ELvckxoswXK5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qAfjlnIjyIjA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}