{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5AH8MLYjfwgp",
        "VMtpSPyriRkl",
        "ubaprtVKf88y",
        "D12fghhagRjE",
        "SDKeqnp-gqyc",
        "jk6_6oiZg5Dl",
        "R79sGteNkpVT",
        "_NKoVBUUkw0D",
        "1KM1qtISk-6T",
        "ZhnBUrQTl_BT",
        "ZBXkyZRzmSdj",
        "GNDNz9V5m_EU",
        "GVqmZ6rRoDTd",
        "njpl5RHiosuU",
        "_ryxqKXUo6Ic",
        "lZQPvZfZszkC",
        "NyE94c4JtDWa",
        "vk7QPjtIv4rZ",
        "qD43WO8o5LaU",
        "2189jWXqwNhA",
        "JBBoS9QowA6Z",
        "AvQezV_qx8g4",
        "6nA1NdjV-tYv",
        "PSo23e2IHX2n",
        "ELvckxoswXK5",
        "8XANfxe7IFA5",
        "cKUD3NJddNwC",
        "2Tuqz1acz2js"
      ],
      "authorship_tag": "ABX9TyPY5a1NgrKTq9EWIOJ5OaK+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leucocitokiller/Proyecto-Fina-NLP/blob/main/Proyecto_final_NLP_Redes_Neuronales_Libenson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducción.**"
      ],
      "metadata": {
        "id": "iynTgO2qzJTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este trabajo práctico se aborda el análisis y clasificación de opiniones de usuarios mediante técnicas de Procesamiento de Lenguaje Natural (NLP) y Machine Learning. Se emplean dos conjuntos de datos distintos, provenientes de plataformas reconocidas: Yelp, que contiene reseñas de locales de comida, y Amazon, que incluye comentarios sobre productos."
      ],
      "metadata": {
        "id": "4_kaSM_zJAqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objetivos.**"
      ],
      "metadata": {
        "id": "5ZXBeSKazPVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo principal es desarrollar un modelo capaz de identificar automáticamente si un comentario es positivo o negativo, independientemente de la temática o sector al que pertenezca. Para ello, se aplican diferentes herramientas y técnicas propias del NLP, tales como el tokenizado, lemmatización, entre otras, que permiten transformar los textos en formatos adecuados para su análisis computacional.\n",
        "\n",
        "Posteriormente, se prueba una variedad de modelos de machine learning para evaluar cuál es el más efectivo en la clasificación de sentimientos en ambos datasets. Esto incluye desde modelos clásicos hasta técnicas más avanzadas, buscando generalizar el aprendizaje para que el modelo pueda detectar la polaridad del comentario más allá del contexto específico.\n",
        "\n",
        "Este enfoque facilita no solo el entendimiento de las opiniones expresadas por los usuarios, sino que también permite desarrollar sistemas automatizados de análisis de sentimientos útiles en distintas aplicaciones comerciales y de investigación."
      ],
      "metadata": {
        "id": "ZCSpjSaCJLL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Origen de los datos.**"
      ],
      "metadata": {
        "id": "DqzsZE2ozTtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos pertenecen a una adaptación de los comentarios de yelp y amazon y fueron obtenidos del siguiente link de Github:\n",
        "\n",
        "https://github.com/luisFernandoCastellanosG/Machine_learning/blob/master/2-Deep_Learning/PLN/Datasets/DataSetOpiniones.zip\n",
        "\n",
        "Datos del autor:\n",
        "\n",
        "https://github.com/luisFernandoCastellanosG/Machine_learning/blob/master/2-Deep_Learning/PLN/Datasets/readme.md\n",
        "\n"
      ],
      "metadata": {
        "id": "tXedftW6L9Kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Desarrollo.**"
      ],
      "metadata": {
        "id": "UfJPcx_uzjiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importación de Librerías.**"
      ],
      "metadata": {
        "id": "5AH8MLYjfwgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "#-----librerias para trabajar NLP\n",
        "!python -m spacy download es_core_news_md\n",
        "import spacy\n",
        "import es_core_news_md\n",
        "#es_core_news_md Medium (modelo mediano):\n",
        "#Es más pesado y más lento que el sm, pero mucho más preciso. Tiene vectores de palabras, entiende mejor el significado de las palabras.\n",
        "\n",
        "#-----instalación d librerias para análisis de sentimientos.\n",
        "!pip install spacy spacy-transformers\n",
        "!pip install pysentimiento\n",
        "from pysentimiento import create_analyzer\n",
        "\n",
        "#----librerias para normalización de textos\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#----librerias para graficar y wordcloud.\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#----librerías para trabajar con TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#----libreria para trabajar con BoW.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#----librerias para Machine learning\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
        "#----librerias de Redes Neuronales.\n",
        "# Importamos el Tokenizer para procesar el texto y convertirlo en secuencias numéricas\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Importamos la función para rellenar las secuencias con ceros y asegurarnos que todas tengan la misma longitud\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Importamos el modelo secuencial de Keras, que permite apilar capas de manera lineal\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "# Importamos las capas necesarias:\n",
        "# - Embedding: para convertir índices de palabras en vectores densos.\n",
        "# - SimpleRNN: una capa recurrente que procesa secuencias de datos.\n",
        "# - Dense: una capa totalmente conectada, utilizada para la salida del modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "64jaT-pwfyzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Procesamiento de la Fuente de Datos.**"
      ],
      "metadata": {
        "id": "VMtpSPyriRkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexión con la fuente de datos.\n"
      ],
      "metadata": {
        "id": "ubaprtVKf88y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se cargan dos dataset desde Github que contienen comentarios sobre celulares (Amanzon) y servicio de restaurantes (Yelp). Ambos dataset se unifican para tener un mayor volumen de datos para analizar.\n",
        "\n",
        "Los mismos estan compuestos por dos columnas, una con los comentarios de cada usario registrado y otra con el valor asignado a ese comentario.\n",
        "Si el comentario tiene un valor 1 se lo considera positivo y si tiene valor 2 como negativo."
      ],
      "metadata": {
        "id": "KU4pkuDmqq--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario con las fuentes y sus URLs\n",
        "filepath_dict = {\n",
        "    'yelp': 'https://raw.githubusercontent.com/Leucocitokiller/Proyecto-Fina-NLP/main/yelp_comentarios.csv',\n",
        "    'amazon': 'https://raw.githubusercontent.com/Leucocitokiller/Proyecto-Fina-NLP/main/amazon_cells_comentarios.csv'\n",
        "\n",
        "}\n",
        "\n",
        "df_list = []\n",
        "for source, filepath in filepath_dict.items():\n",
        "    df = pd.read_csv(filepath, names=['Comentario', 'Valor'], sep=';', encoding='latin-1')\n",
        "    df['Origen'] = source  # se agrega una nueva columna para saber si los comentarios son de Yelp o Amazon.\n",
        "    df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list)\n",
        "df.head(1100)"
      ],
      "metadata": {
        "id": "QA3En5EYgAtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalización de la Fuente de datos.\n"
      ],
      "metadata": {
        "id": "Eagv-jaJgM_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eliminación de signos de puntuación."
      ],
      "metadata": {
        "id": "D12fghhagRjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de función para eliminar los signos de puntuación utilizando re, pero considerando no borrar las vocales con acento.\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Normaliza el texto a NFKD para separar letras y sus tildes\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    # Elimina los caracteres diacríticos (como las tildes)\n",
        "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
        "    # Elimina todo lo que no sea letras, números o espacios\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Aplicar la función a la columna 'review_lower'\n",
        "df['Comentarios'] = df['Comentario'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "TlTn8VuygQxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ez4O1zkbhB2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reducir a minúsculas el texto."
      ],
      "metadata": {
        "id": "SDKeqnp-gqyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column 'Comentarios_lower' with lowercase values from 'Comentario'\n",
        "df['Comentarios_lower'] = df['Comentarios'].str.lower()"
      ],
      "metadata": {
        "id": "ExcMpIx7gw-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_O0hOspchMl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convertir a número la columna Valor para su postprocesamiento."
      ],
      "metadata": {
        "id": "jk6_6oiZg5Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos la columna rating a valor numérico\n",
        "df['Valor'] = pd.to_numeric(df['Valor'], errors='coerce')"
      ],
      "metadata": {
        "id": "a_urHIsIg7Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Valor']"
      ],
      "metadata": {
        "id": "yUwGYj_jhIud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP**"
      ],
      "metadata": {
        "id": "39XV91NgkM9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Procesamiento."
      ],
      "metadata": {
        "id": "R79sGteNkpVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generación del objeto de SPacy para utilizar en el procesamiento del texto en español."
      ],
      "metadata": {
        "id": "_NKoVBUUkw0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de aplicar técnicas de análisis de sentimiento, se debe realizar un preprocesamiento del texto que prepare los datos para ser interpretados por modelos de NLP.\n",
        "En este paso, se lleva a cabo la generación del objeto de spaCy para trabajar con el idioma español, lo cual permite aprovechar herramientas lingüísticas como la tokenización, lematización"
      ],
      "metadata": {
        "id": "mJtkLU3WP1cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = es_core_news_md.load()"
      ],
      "metadata": {
        "id": "aiW_XvTOkm2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convertir texto a minúsculas y Tokenización."
      ],
      "metadata": {
        "id": "1KM1qtISk-6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una de las primeras transformaciones aplicadas es la conversión del texto a minúsculas, lo que ayuda a normalizar las palabras y evitar que el modelo interprete como diferentes aquellas que solo varían en el uso de mayúsculas (por ejemplo, \"Bueno\" y \"bueno\"). A continuación, se realiza la tokenización, que consiste en dividir el texto en unidades mínimas llamadas tokens (como palabras, signos de puntuación o números), facilitando el análisis posterior del lenguaje."
      ],
      "metadata": {
        "id": "Qm49X2mKP_L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Comentarios_tokenizados'] = df['Comentarios_lower'].apply(lambda text: nlp(text))\n",
        "df[['Comentarios_lower','Comentarios_tokenizados']].head()"
      ],
      "metadata": {
        "id": "uVF3ar5olBDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remoción de StopWords"
      ],
      "metadata": {
        "id": "ZhnBUrQTl_BT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante la eliminación de stopwords, que son palabras vacías o de bajo contenido semántico (como “el”, “la”, “y”, “de”), se identificó que en algunos casos su remoción podía afectar negativamente el sentido original de las frases. Esto es particularmente relevante en reseñas donde expresiones comunes dependen de ciertas palabras funcionales para conservar su significado completo.\n",
        "\n",
        "Por esta razón, fue necesario generar un listado personalizado de palabras que debían conservarse.\n",
        "\n",
        "Esto permitió preservar la coherencia y contexto de los comentarios, evitando que el modelo perdiera información clave para la detección del sentimiento."
      ],
      "metadata": {
        "id": "oMmYeo9lQZbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de palabras que NO queremos eliminar (tienen carga emocional)\n",
        "palabras_sentimiento = {\n",
        "    # Positivas\n",
        "    \"bueno\", \"buena\",\"si\",\"buenísimo\", \"excelentes\", \"excelente\", \"genial\", \"maravilloso\", \"maravilla\", \"fantástico\", \"fabuloso\", \"increíble\",\n",
        "    \"perfecto\", \"perfecta\", \"agradable\", \"satisfecho\", \"satisfecha\", \"contento\", \"contenta\", \"encantado\", \"encantada\",\n",
        "    \"amable\", \"simpático\", \"simpática\", \"rápido\", \"rápida\", \"cómodo\", \"cómoda\", \"eficaz\", \"eficiente\", \"fácil\",\n",
        "    \"recomendable\", \"ideal\", \"espectacular\", \"feliz\", \"brillante\", \"cumplió\", \"cumple\", \"funciona\", \"funciona bien\",\n",
        "    \"inmejorable\", \"confiable\", \"duradero\", \"cumplidor\", \"seguro\", \"preciso\", \"elegante\", \"atento\", \"responsable\",\n",
        "    \"acertado\", \"destacado\", \"excepcional\", \"impecable\", \"sensacional\", \"útil\", \"accesible\", \"económico\", \"funcional\",\n",
        "    \"intuitivo\", \"conveniente\", \"hermoso\", \"linda\", \"precioso\", \"excelente calidad\", \"vale la pena\",\n",
        "\n",
        "    # Negativas\n",
        "    \"malo\",\"no\", \"mala\", \"mal\", \"pésimo\", \"pésima\",\"nunca\", \"horrible\", \"fatal\", \"insoportable\", \"lento\", \"lenta\", \"incómodo\", \"incómoda\",\n",
        "    \"decepcionante\", \"decepcionado\", \"decepcionada\", \"sucio\", \"sucia\", \"caro\", \"cara\", \"inútil\", \"deficiente\", \"desagradable\",\n",
        "    \"complicado\", \"problemático\", \"estafa\", \"engañado\", \"engañada\", \"roto\", \"rota\", \"desastroso\", \"error\", \"errores\",\n",
        "    \"retraso\", \"tardanza\", \"frágil\", \"inestable\", \"poco fiable\", \"nunca más\", \"no volveré\", \"no recomiendo\", \"no sirve\",\n",
        "    \"no funciona\", \"arruinado\", \"falló\", \"fallando\", \"demora\", \"pésima atención\", \"servicio malo\", \"mala calidad\", \"molesto\",\n",
        "    \"defecto\", \"problemas\", \"fallas\", \"sin sentido\", \"basura\", \"pérdida de dinero\", \"decepción\"\n",
        "}\n",
        "\n",
        "# Actualizamos spaCy para que NO considere esas palabras como stopwords\n",
        "for palabra in palabras_sentimiento:\n",
        "    lex = nlp.vocab[palabra]\n",
        "    lex.is_stop = False\n",
        "\n",
        "def parse_and_remove_stopwords(doc):\n",
        "    \"\"\"\n",
        "    Remueve las stopwords de un objeto spaCy Doc.\n",
        "    \"\"\"\n",
        "    # Filtrar stopwords y obtener los tokens como texto\n",
        "    tokens_filtrados = [token.text for token in doc if not token.is_stop]\n",
        "    return tokens_filtrados\n",
        "\n",
        "# Aplicar la función al DataFrame\n",
        "df['Comentarios_sin_StopWords'] = df['Comentarios_tokenizados'].apply(parse_and_remove_stopwords)\n",
        "\n",
        "df[['Comentarios_tokenizados','Comentarios_sin_StopWords']].head()"
      ],
      "metadata": {
        "id": "2_cr__EqmG4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lematizado."
      ],
      "metadata": {
        "id": "ZBXkyZRzmSdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a aplicar la lematización, una técnica que permite reducir cada palabra a su forma base o \"lema\". Por ejemplo, palabras como “comprando”, “compré” o “comprarían” se transforman en “comprar”. Esto es esencial para evitar la dispersión semántica y lograr que el modelo reconozca distintas variantes de una palabra como una misma entidad."
      ],
      "metadata": {
        "id": "sYr3W0kMQwwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lematizar_sin_stopwords(doc):\n",
        "    \"\"\"\n",
        "    Devuelve una lista de lemas excluyendo las stopwords.\n",
        "\n",
        "    Parámetro:\n",
        "    - doc: objeto spaCy Doc\n",
        "\n",
        "    Retorna:\n",
        "    - Lista de lemas (str) sin stopwords\n",
        "    \"\"\"\n",
        "    return [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
        "\n",
        "# Aplicar la función y guardar el resultado en una nueva columna\n",
        "df['Comentarios_lema'] = df['Comentarios_tokenizados'].apply(lematizar_sin_stopwords)\n",
        "\n",
        "df[['Comentarios_tokenizados','Comentarios_lema']].head(20)"
      ],
      "metadata": {
        "id": "DsRRS29ImVnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesamiento"
      ],
      "metadata": {
        "id": "9bW_hSCRm02p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conteo de Palabras mas comunes."
      ],
      "metadata": {
        "id": "GNDNz9V5m_EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como parte del análisis exploratorio, se realizó un conteo de las palabras más frecuentes dentro de los comentarios.\n",
        "Esta etapa permite identificar los términos que predominan en el lenguaje utilizado por los usuarios y detectar patrones o temas recurrentes en las opiniones.\n",
        "\n",
        "Para un análisis más detallado, el conteo se dividió entre los comentarios de Yelp y Amazon, con el fin de comparar el vocabulario característico de cada plataforma. Mientras Yelp tiende a centrarse en experiencias relacionadas con servicios (como restaurantes o locales comerciales), Amazon refleja opiniones sobre productos, lo cual se evidencia en las diferencias léxicas observadas entre ambos conjuntos de datos."
      ],
      "metadata": {
        "id": "7xH0ak7NRHlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graficar_palabras_comunes(df, origen, top_n=10):\n",
        "    # Filtrar y aplanar los lemas\n",
        "    lemas = [lema for lemas in df[df['Origen'] == origen]['Comentarios_lema'] for lema in lemas]\n",
        "    conteo = Counter(lemas).most_common(top_n)\n",
        "\n",
        "    # Separar palabras y frecuencias\n",
        "    palabras, frecuencias = zip(*conteo)\n",
        "\n",
        "    # Crear gráfico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(palabras, frecuencias, color='skyblue')\n",
        "    plt.xlabel('Frecuencia')\n",
        "    plt.title(f'Top {top_n} Palabras Más Comunes - {origen.capitalize()}')\n",
        "    plt.gca().invert_yaxis()  # Poner la palabra más común arriba\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Graficar para Yelp\n",
        "graficar_palabras_comunes(df, 'yelp')\n",
        "\n",
        "# Graficar para Amazon\n",
        "graficar_palabras_comunes(df, 'amazon')"
      ],
      "metadata": {
        "id": "cHPKUNjjoJQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conteo de bigramas más comunes."
      ],
      "metadata": {
        "id": "GVqmZ6rRoDTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además del análisis de palabras individuales, se llevó a cabo un conteo de bigramas (pares de palabras consecutivas) con el objetivo de capturar expresiones más completas y contextuales utilizadas por los usuarios en sus comentarios. A diferencia del análisis unigram (una sola palabra), los bigramas permiten identificar frases frecuentes que pueden tener un valor semántico más claro, como \"muy bueno\", \"no funciona\", \"excelente producto\", entre otros."
      ],
      "metadata": {
        "id": "wDVQ4InbRZ7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from itertools import tee\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generar_bigramas(lista):\n",
        "    \"\"\"Devuelve bigramas como tuplas a partir de una lista de palabras\"\"\"\n",
        "    a, b = tee(lista)\n",
        "    next(b, None)\n",
        "    return list(zip(a, b))\n",
        "\n",
        "def graficar_bigramas_comunes(df, origen, top_n=10):\n",
        "    # Filtrar solo los comentarios del origen y generar bigramas\n",
        "    bigramas = [\n",
        "        bigrama\n",
        "        for lemas in df[df['Origen'] == origen]['Comentarios_lema']\n",
        "        for bigrama in generar_bigramas(lemas)\n",
        "    ]\n",
        "\n",
        "    conteo = Counter(bigramas).most_common(top_n)\n",
        "\n",
        "    # Convertir tuplas de bigramas a string para graficar\n",
        "    etiquetas = [' '.join(b) for b, _ in conteo]\n",
        "    frecuencias = [f for _, f in conteo]\n",
        "\n",
        "    # Crear gráfico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(etiquetas, frecuencias, color='mediumseagreen')\n",
        "    plt.xlabel('Frecuencia')\n",
        "    plt.title(f'Top {top_n} Bigramas Más Comunes - {origen.capitalize()}')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejemplo de uso\n",
        "graficar_bigramas_comunes(df, 'yelp')\n",
        "graficar_bigramas_comunes(df, 'amazon')\n"
      ],
      "metadata": {
        "id": "_B3v3nOknL2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WordClouds"
      ],
      "metadata": {
        "id": "tn6x4GaEoYRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para complementar el análisis exploratorio, se generaron nubes de palabras que representan gráficamente la frecuencia de aparición de términos en los comentarios. Este tipo de visualización permite identificar rápidamente las palabras y frases más utilizadas por los usuarios, otorgando una vista intuitiva del contenido predominante en cada dataset.\n",
        "\n",
        "Se realizaron dos tipos de word clouds:\n",
        "\n",
        "Una para monogramas, es decir, palabras individuales.\n",
        "\n",
        "Otra para bigramas, que agrupa las dos palabras consecutivas más frecuentes.\n",
        "\n",
        "Ambos casos compara a Yelp y Amazon."
      ],
      "metadata": {
        "id": "JJ__43PrRsvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud Yelp."
      ],
      "metadata": {
        "id": "VCXSZ4glokBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el DataFrame\n",
        "df_yelp = df[df['Origen'] == 'yelp']\n",
        "\n",
        "# Unir todos los lemas en un solo string (comentarios lematizados ya están en listas)\n",
        "texto_yelp = ' '.join([' '.join(lemas) for lemas in df_yelp['Comentarios_lema']])\n",
        "\n",
        "# Crear la nube de palabras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto_yelp)\n",
        "\n",
        "# Mostrar la nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nube de Palabras - Comentarios de Yelp\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UXGDKZCaocLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud Amazon."
      ],
      "metadata": {
        "id": "njpl5RHiosuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el DataFrame\n",
        "df_amazon = df[df['Origen'] == 'amazon']\n",
        "\n",
        "# Unir todos los lemas en un solo string (comentarios lematizados ya están en listas)\n",
        "texto_amazon = ' '.join([' '.join(lemas) for lemas in df_amazon['Comentarios_lema']])\n",
        "\n",
        "# Crear la nube de palabras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto_amazon)\n",
        "\n",
        "# Mostrar la nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nube de Palabras - Comentarios de Yelp\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PHfxMdccou0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud + Bigramas."
      ],
      "metadata": {
        "id": "_ryxqKXUo6Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_bigramas_spacy(df, origen, top_n=50):\n",
        "    \"\"\"\n",
        "    Genera bigramas usando spaCy a partir de la columna 'Comentarios_Lema', sin stopwords.\n",
        "    Luego genera una nube de palabras.\n",
        "    \"\"\"\n",
        "    # Filtrar los comentarios por 'origen' (por ejemplo, 'yelp' o 'amazon')\n",
        "    comentarios = df[df['Origen'] == origen]['Comentarios_sin_StopWords']\n",
        "\n",
        "    # Generar bigramas\n",
        "    bigramas = []\n",
        "    for comentario in comentarios:\n",
        "        # Crear un Doc de spaCy a partir de la lista de lemas (de la columna 'Comentarios_Lema')\n",
        "        doc = nlp(' '.join(comentario))  # Unimos la lista de lemas y lo procesamos con spaCy\n",
        "        # Extraer bigramas\n",
        "        for i in range(len(doc) - 1):\n",
        "            if not doc[i].is_stop and not doc[i+1].is_stop:  # Asegurarse de que no sean stopwords\n",
        "                bigramas.append((doc[i].lemma_, doc[i+1].lemma_))\n",
        "\n",
        "    # Contar los bigramas más comunes\n",
        "    conteo_bigramas = Counter(bigramas).most_common(top_n)\n",
        "\n",
        "    # Convertir los bigramas a formato texto \"palabra1 palabra2\"\n",
        "    bigramas_texto = {' '.join(bigrama): freq for bigrama, freq in conteo_bigramas}\n",
        "\n",
        "    # Generar la nube de palabras de los bigramas\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(bigramas_texto)\n",
        "\n",
        "    # Mostrar la nube\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Word Cloud de Bigramas - {origen.capitalize()}\")\n",
        "    plt.show()\n",
        "\n",
        "# Generar la nube de bigramas para Yelp y Amazon\n",
        "generar_bigramas_spacy(df, 'yelp')\n",
        "generar_bigramas_spacy(df, 'amazon')"
      ],
      "metadata": {
        "id": "qW644mkPo8qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###🚀 Análisis de sentimiento en español con pysentimiento"
      ],
      "metadata": {
        "id": "3h4HlXQzpWl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez preprocesados los textos, se aplicó un modelo de análisis de sentimiento específicamente entrenado para el idioma español utilizando la librería pysentimiento.\n",
        "\n",
        "pysentimiento permite detectar si un comentario es positivo, negativo o neutral, lo cual resulta fundamental para evaluar la percepción general de los usuarios sobre un producto o servicio. A diferencia de otros enfoques más simples, este modelo considera la estructura gramatical y el significado global de la oración, lo que mejora notablemente la precisión, especialmente en expresiones ambiguas o sarcásticas."
      ],
      "metadata": {
        "id": "IxdlTr29SR_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear analizador de sentimientos\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "\n",
        "# Aplicar a una columna de texto\n",
        "df['Sentimiento'] = df['Comentario'].apply(lambda x: analyzer.predict(x).output)\n",
        "# Sentimiento solo guarda lo predicho (POS, NEU o NEG)\n",
        "\n",
        "df['Probabilidad'] = df['Comentario'].apply(lambda x: analyzer.predict(x).probas)\n",
        "#Ese diccionario contiene la probabilidad de cada clase: positivo, neutro, negativo Ejemplo: {'POS': 0.84, 'NEU': 0.10, 'NEG': 0.06}."
      ],
      "metadata": {
        "id": "r5feGF2Gpias"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 📊  Gráfico de barras de frecuencia de sentimientos"
      ],
      "metadata": {
        "id": "lZQPvZfZszkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, x='Sentimiento', order=['POS', 'NEU', 'NEG'], palette='pastel')\n",
        "plt.title('Distribución de Sentimientos totales entre Yelp y Amazon')\n",
        "plt.xlabel('Sentimiento')\n",
        "plt.ylabel('Cantidad de Comentarios')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ddaD7cous3SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribución de los sentimientos."
      ],
      "metadata": {
        "id": "NyE94c4JtDWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentimiento'].value_counts().plot.pie(\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    labels=['Positivo', 'Neutro', 'Negativo'],\n",
        "    colors=['lightgreen', 'lightblue', 'salmon']\n",
        ")\n",
        "plt.title('Distribución porcentual de Sentimientos')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dI2qGwfVs837"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Análisis de Confianza para filtrar comentarios con baja certeza"
      ],
      "metadata": {
        "id": "N9Ehqc_htP8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego de aplicar el modelo de análisis de sentimiento con pysentimiento, se incorporó una etapa adicional para evaluar la confianza de las predicciones. Este análisis se basa en las probabilidades asignadas a cada clase (positivo, negativo o neutral), lo que permite identificar qué tan seguro está el modelo respecto a cada clasificación realizada.\n",
        "\n",
        "Con esta información se implementó un filtro de confianza, excluyendo o marcando aquellos comentarios cuya predicción tiene baja certeza (por ejemplo, menor al 60%). Esta estrategia ayuda a reducir errores en el análisis general, ya que evita tomar decisiones basadas en clasificaciones inciertas o ambiguas.\n",
        "\n",
        "Además, el análisis de confianza permite estudiar qué tipos de comentarios generan más dudas en el modelo, lo que puede ser útil para mejorar el preprocesamiento, ajustar umbrales, o incluso etiquetar manualmente ciertos casos en futuras iteraciones del modelo."
      ],
      "metadata": {
        "id": "vqG1qPzUSzN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Máxima probabilidad (nivel de certeza del modelo)\n",
        "df['Confianza'] = df['Probabilidad'].apply(lambda x: max(x.values()))  # En este caso, de la lista {'POS': 0.84, 'NEU': 0.10, 'NEG': 0.06} sólo guarda 0.84 que es el valor mayor\n",
        "\n",
        "# Filtrar comentarios cuya confianza sea menor a 0.6\n",
        "comentarios_baja_confianza = df[df['Confianza'] < 0.6]\n",
        "comentarios_alta_confianza = df[df['Confianza'] >= 0.6]\n",
        "# Ver los primeros resultados\n",
        "#comentarios_baja_confianza[['Comentarios', 'Sentimiento', 'Confianza']]"
      ],
      "metadata": {
        "id": "cp_TPbgYtUPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribución de los comentarios filtrados."
      ],
      "metadata": {
        "id": "Np0Wbkh-t9ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Confianza'] >= 0.6]['Sentimiento'].value_counts().plot.pie(\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    labels=['Positivo', 'Neutro', 'Negativo'],\n",
        "    colors=['lightgreen', 'lightblue', 'salmon']\n",
        ")\n",
        "plt.title('Distribución porcentual de Sentimientos con alta confianza')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DKGk25nltsFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribución de la Confianza de los comentarios."
      ],
      "metadata": {
        "id": "8UwgeOBbuhWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data=df, x='Confianza', bins=20, kde=True, color='skyblue')\n",
        "plt.axvline(0.6, color='red', linestyle='--', label='Umbral 0.6')\n",
        "plt.title('Distribución de Confianza del Sentimiento')\n",
        "plt.xlabel('Confianza')\n",
        "plt.ylabel('Cantidad de Comentarios')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W1mX2p80uabR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comentarios_baja_confianza[['Comentario', 'Sentimiento', 'Confianza', 'Probabilidad']].sort_values(by='Confianza').head(20)\n"
      ],
      "metadata": {
        "id": "4tHWg2UiT5Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pruebas de Modelos de Machine Learning.**"
      ],
      "metadata": {
        "id": "vk7QPjtIv4rZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto, se realizará un análisis de texto con el objetivo de predecir una variable numérica que nos indica positvo (para 1) y negativo (para 0), a partir de opiniones o reseñas escritas por usuarios.\n",
        "\n",
        "\n",
        "Para convertir los textos en datos numéricos que puedan ser procesados por modelos de machine learning, seutilizaran dos técnicas de representación de texto:TF-IDF (Term Frequency-Inverse Document Frequency) y Bag of Words (BoW).\n",
        "\n",
        "\n",
        "TF-IDF pondera la frecuencia de las palabras en cada documento ajustándola según su frecuencia inversa en todo el corpus, dando mayor peso a términos distintivos y reduciendo la influencia de palabras comunes.\n",
        "\n",
        "Bag of Words representa cada documento como un vector que indica la frecuencia de cada palabra, sin considerar el orden ni la relevancia contextual.\n",
        "\n",
        "Estos vectores van a ser utilizados como entrada para un modelo de regresión logística, que permitirá predecir la variable objetivo asociada a cada texto, en este caso si los comentarios son positivos o negativos.\n",
        "\n",
        "Adicionalmente, se incorporará un modelo de deep learning utilizando la biblioteca Keras, que aprvechando redes neuronales para capturar patrones más complejos en los textos, incluyendo relaciones contextuales y secuenciales entre palabras que no pueden ser detectadas por las representaciones tradicionales.\n",
        "\n",
        "Se entrenarán y evaluarán los tres modelos —regresión lineal con Bag of Words, regresión lineal con TF-IDF y red neuronal profunda con Keras— para comparar su desempeño predictivo.\n",
        "\n",
        "La evaluación incluirá métricas adecuadas para regresión y análisis de generalización, con el fin de identificar cuál enfoque es más efectivo para este problema específico.\n",
        "\n",
        "Este análisis permitirá no solo comparar técnicas clásicas y modernas de procesamiento de texto, sino también obtener insights sobre la relevancia y el impacto de las palabras y estructuras en la predicción, mejorando la comprensión del comportamiento del modelo y la calidad de las predicciones."
      ],
      "metadata": {
        "id": "OLYy9hwkE4Ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### División de datos de entrenamiento y prueba."
      ],
      "metadata": {
        "id": "qD43WO8o5LaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['Comentario'], df['Valor'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jkK0y7oy5Z_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión Logística."
      ],
      "metadata": {
        "id": "2189jWXqwNhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando TF-IFD."
      ],
      "metadata": {
        "id": "JBBoS9QowA6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (Term Frequency - Inverse Document Frequency) es una técnica de procesamiento de texto utilizada para evaluar la importancia de una palabra dentro de un conjunto de documentos. Se basa en dos conceptos:\n",
        "\n",
        "TF (Frecuencia de Término): Mide cuántas veces aparece un término en un documento específico, comparado con el número total de términos en ese documento. Esto ayuda a capturar cuán relevante es una palabra dentro de un documento en particular.\n",
        "\n",
        "IDF (Frecuencia Inversa de Documentos): Mide la importancia de una palabra dentro de un conjunto de documentos. Si una palabra aparece en muchos documentos, tiene menos valor. La fórmula es:\n",
        "\n",
        "Esto ayuda a reducir el peso de las palabras que aparecen frecuentemente en todos los documentos (como \"el\", \"y\", \"de\"), ya que no agregan mucha información.\n",
        "\n",
        "Así, la importancia de un término en un documento depende tanto de su frecuencia en ese documento como de cuán común es en todo el conjunto de documentos."
      ],
      "metadata": {
        "id": "Z5Qu0o3RwyoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cálculo de TF-IDF con TfidVetorizer y analisis de n-gramas."
      ],
      "metadata": {
        "id": "AvQezV_qx8g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # TFIDF espera trabajar con strings y  no listas, por lo que se procede a crear una nueva columna con los datos tokenizados en formato str.\n",
        "df['Comentarios_sin_StopWords_str'] = df['Comentarios_sin_StopWords'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Crear el vectorizador\n",
        "tfidfvectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
        "#inlcuyo bigramas y trigramas para que le de contexto a los comentarios. Esto me permite ver un \"No conforme\" y no solamente le \"No\" y el \"Conforme\" por separado.\n",
        "\n",
        "# Ajustar y transformar\n",
        "tfidf_matrix = tfidfvectorizer.fit_transform(df['Comentarios_sin_StopWords_str'])\n",
        "\n",
        "# Obtener los términos\n",
        "features = tfidfvectorizer.get_feature_names_out()\n",
        "\n",
        "# Convertir la matriz a DataFrame\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=features)\n",
        "\n",
        "# Sumar TF-IDF por columna\n",
        "tfidf_scores = df_tfidf.sum().sort_values(ascending=False)\n",
        "\n",
        "# Mostrar top 10\n",
        "print(\"🔝 Top 10 n-gramas por score TF-IDF:\")\n",
        "print(tfidf_scores.head(10).round(3))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yOA1KulbyJG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame auxiliar con el tipo de n-grama\n",
        "df_scores = pd.DataFrame({\n",
        "    'ngram': tfidf_scores.index,\n",
        "    'score': tfidf_scores.values,\n",
        "    'tipo': tfidf_scores.index.to_series().apply(lambda x: f'{len(x.split())}-grama')\n",
        "})\n",
        "\n",
        "# Ver los 5 más importantes por tipo\n",
        "top_n = 5\n",
        "for tipo in ['1-grama', '2-grama', '3-grama']:\n",
        "    print(f\"\\n🔝 Top {top_n} {tipo}s:\")\n",
        "    print(df_scores[df_scores['tipo'] == tipo].head(top_n).to_string(index=False))"
      ],
      "metadata": {
        "id": "8TncVynMzZlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El análisis de los n-gramas (1, 2 y 3 palabras) revela una fuerte tendencia negativa en los comentarios analizados.\n",
        "\n",
        "Esto se evidencia principalmente por:\n",
        "\n",
        "La presencia dominante de la palabra \"no\" como unigram (1-grama) más relevante, indicando una alta frecuencia de negaciones.\n",
        "\n",
        "Los bigramas y trigramas refuerzan esta tendencia negativa, con frases como \"no volveremos\", \"no volvere\", \"no funciona\", \"no recomendaria\", \"no vale pena\" y \"no compre producto\", todas las cuales reflejan insatisfacción o malas experiencias.\n",
        "\n",
        "Aun así, hay menciones positivas como \"buena comida servicio\", pero estas son menos frecuentes o tienen menor peso que las negativas."
      ],
      "metadata": {
        "id": "b4VhVp3p41Q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ajuste de datos de Entrenamiento."
      ],
      "metadata": {
        "id": "jGzhxUtp6DAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajustamos el vectorizador TF-IDF con los datos de entrenamiento y test  transformando esos datos en una matriz numérica."
      ],
      "metadata": {
        "id": "OREs2HSJ-9jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar y transformar los datos de entrenamiento\n",
        "X_train_tfidf = tfidfvectorizer.fit_transform(X_train)\n",
        "# Transformar los datos de prueba\n",
        "X_test_tfidf = tfidfvectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "C9X3Y3tX6JQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generación y prueba de modelo Regresión Logística."
      ],
      "metadata": {
        "id": "4zXnyKl47GSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un modelo de regresión logística\n",
        "# Abajo tenés un código con los parámetros expresados de forma que puedas ir modificandolos\n",
        "model_log_reg = LogisticRegression() #Instanciamos el modelo\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_log_reg.fit(X_train_tfidf, y_train) # Fiteamos, es decir, el modelo aprende a partir de los datos de entrenamiento\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "y_pred_log_reg = model_log_reg.predict(X_test_tfidf) # Predecir"
      ],
      "metadata": {
        "id": "lmGzeGnU7NlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluación del Modelo."
      ],
      "metadata": {
        "id": "BKMGMFHX8OKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusión."
      ],
      "metadata": {
        "id": "i8zfSea79_Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Matriz de confusión\n",
        "\n",
        "# La Matriz de Confusión es útil para Muestra los aciertos y errores del modelo organizados por clase.\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_log_reg)\n",
        "labels = ['Negativo', 'Positivo']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SZu-1myh8k3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📊 Interpretación de los resultados:\n",
        "TP (Verdaderos Positivos) = 148: Casos positivos correctamente clasificados como positivos.\n",
        "\n",
        "TN (Verdaderos Negativos) = 181: Casos negativos correctamente clasificados como negativos.\n",
        "\n",
        "FP (Falsos Positivos) = 28: Casos negativos mal clasificados como positivos.\n",
        "\n",
        "FN (Falsos Negativos) = 33: Casos positivos mal clasificados como negativos."
      ],
      "metadata": {
        "id": "r9XnpcfN_efX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La matriz de confusión muestra un buen desempeño del modelo:\n",
        "- 181 verdaderos negativos y 148 verdaderos positivos indican una buena capacidad para clasificar correctamente ambas clases.\n",
        "- Sin embargo, hay 28 falsos positivos y 33 falsos negativos, lo que sugiere que el modelo comete algunos errores, especialmente en la identificación de la clase positiva.\n",
        "- Estos errores podrían ser relevantes dependiendo del contexto del problema (por ejemplo, si detectar positivos es crítico)."
      ],
      "metadata": {
        "id": "cbcBvQDf_jVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curva ROC AUC."
      ],
      "metadata": {
        "id": "YAkrMHlM-DEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El ROC AUC (Receiver Operating Characteristic - Area Under Curve) es una métrica que mide la capacidad del modelo para distinguir entre clases (positiva y negativa), evaluando todas las combinaciones posibles de umbrales de clasificación."
      ],
      "metadata": {
        "id": "K18ta-8I_yhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC: Es una curva que grafica la tasa de verdaderos positivos (TPR) contra la tasa de falsos positivos (FPR) a distintos umbrales.\n",
        "\n",
        "AUC (Area Under Curve): Es el área bajo esa curva, y su valor va de 0 a 1:\n",
        "\n",
        "1.0 = modelo perfecto.\n",
        "\n",
        "0.5 = modelo sin capacidad de clasificación (como adivinar).\n",
        "\n",
        "< 0.5 = peor que adivinar (clasifica al revés)."
      ],
      "metadata": {
        "id": "RUs72JXbAGZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Curva ROC\n",
        "fpr, tpr, _ = roc_curve(y_test, model_log_reg.decision_function(X_test_tfidf))\n",
        "roc_auc = roc_auc_score(y_test, model_log_reg.decision_function(X_test_tfidf))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Área bajo la curva ROC AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o6Iu7ehz9ZCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📈 Interpretación de tu resultado (AUC = 0.89):\n",
        "El valor 0.89 indica que el modelo tiene una alta capacidad para distinguir entre clases.\n",
        "\n",
        "En promedio, hay un 89% de probabilidad de que el modelo asigne un mayor score a una instancia positiva que a una negativa.\n",
        "\n",
        "Este resultado sugiere que el modelo está haciendo un buen trabajo, incluso si aún hay algunos falsos positivos o falsos negativos."
      ],
      "metadata": {
        "id": "ENa983zfAKZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas de Predicción."
      ],
      "metadata": {
        "id": "Tzf7JNqq-FnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Accuracy:Para medir qué tan bien predice el modelo en datos nuevos (exactitud).\n",
        "Accuracy mide el porcentaje total de predicciones correctas sobre el total de casos.\n",
        "- Precision: Para medir el costo de un falso positivo es alto (por ejemplo, recomendar una película mala como buena).\n",
        "Precision mide qué proporción de las predicciones positivas hechas por el modelo son realmente positivas.\n",
        "- Recall: Para medir cuántos de los casos positivos reales fueron capturados por el modelo.\n",
        "- f1 Score: Para medir el promedio armónico entre precisión y recall. Un buen balance si ambas cosas son importantes."
      ],
      "metadata": {
        "id": "EDNMuCVwAUwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Métricas\n",
        "# Accuracy:Para medir qué tan bien predice el modelo en datos nuevos (exactitud).\n",
        "# Accuracy mide el porcentaje total de predicciones correctas sobre el total de casos.\n",
        "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
        "# Precision: Para medir el costo de un falso positivo es alto (por ejemplo, recomendar una película mala como buena).\n",
        "# Precision mide qué proporción de las predicciones positivas hechas por el modelo son realmente positivas.\n",
        "precision = precision_score(y_test, y_pred_log_reg)\n",
        "# Recall: Para medir cuántos de los casos positivos reales fueron capturados por el modelo.\n",
        "recall = recall_score(y_test, y_pred_log_reg)\n",
        "#\n",
        "f1 = f1_score(y_test, y_pred_log_reg)\n",
        "\n",
        "print(\"Métricas de desempeño del modelo:\")\n",
        "print(f\"Accuracy : {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall   : {recall:.2f}\")\n",
        "print(f\"F1 Score : {f1:.2f}\")"
      ],
      "metadata": {
        "id": "yhq9A09B9Y2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados:\n",
        "\n",
        "- Accuracy = 0.82\n",
        "El 82% de todas las predicciones (positivas y negativas) fueron correctas. Es una medida general del rendimiento.\n",
        "Sin embargo, puede ser engañosa si las clases están desbalanceadas.\n",
        "\n",
        "- Precision = 0.80\n",
        "De todas las predicciones positivas que hizo el modelo, el 80% fueron realmente positivas.\n",
        "Es importante si queremos minimizar falsos positivos (por ejemplo, evitar alarmas innecesarias).\n",
        "\n",
        "- Recall = 0.82\n",
        "El modelo identificó correctamente el 82% de todos los casos realmente positivos.\n",
        "Es importante si queremos minimizar falsos negativos (por ejemplo, no dejar pasar casos positivos importantes).\n",
        "\n",
        "- F1 Score = 0.81\n",
        "Es el promedio armónico entre precision y recall. Resume el equilibrio entre ambos.\n",
        " Un F1 de 0.81 indica un buen balance entre identificar positivos y no equivocarse al predecirlos.\n"
      ],
      "metadata": {
        "id": "PpHJs1p1Avpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Validación Cruzada.*"
      ],
      "metadata": {
        "id": "YhVd_UpcIthW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La validación cruzada es una técnica para evaluar la capacidad de generalización de un modelo. Consiste en:\n",
        "\n",
        "Dividir los datos en k partes (folds).\n",
        "\n",
        "Entrenar el modelo con k-1 partes y validar con la parte restante.\n",
        "\n",
        "Repetir esto k veces, cambiando el fold de validación en cada iteración.\n",
        "\n",
        "Calcular el promedio de las métricas obtenidas en cada iteración.\n",
        "\n",
        "Esto reduce el riesgo de que el modelo esté sobreajustado (overfitting) a una única partición de los datos."
      ],
      "metadata": {
        "id": "sB0HBzUiBfUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline que junta vectorizador y modelo\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=5000),\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "# Validación cruzada con 5 particiones (k-fold = 5)\n",
        "scores = cross_val_score(pipeline, df['Comentario'], df['Valor'], cv=5, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(f\"Precisión media con validación cruzada: {scores.mean():.3f}\")\n",
        "print(f\"Desviación estándar: {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "I1TpkwSyI8OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados de la validación cruzada:\n",
        "\n",
        "La precisión media del modelo es 0.807, lo que indica que, en promedio, el modelo acierta con un 80.7% de efectividad\n",
        "en los distintos subconjuntos del conjunto de datos evaluados.\n",
        "\n",
        "La desviación estándar es 0.018, lo que significa que el desempeño del modelo es bastante consistente entre los diferentes folds.\n",
        "Es decir, no hay una gran variación en la precisión dependiendo del conjunto de entrenamiento/validación utilizado.\n",
        "Estos resultados sugieren que el modelo tiene un buen rendimiento general y una buena capacidad de generalización."
      ],
      "metadata": {
        "id": "P1LeKo0ABsZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualización de palabras asociadas a reseñas positivas y negativas."
      ],
      "metadata": {
        "id": "voZXIBS9QDz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta visualización permite identificar las palabras más frecuentes o relevantes en cada grupo de reseñas, separando aquellas asociadas con opiniones positivas de las relacionadas con opiniones negativas.\n",
        "\n",
        "Al analizar estas palabras clave, podemos entender mejor qué aspectos del producto o servicio generan satisfacción o insatisfacción en los usuarios.\n",
        "\n",
        "Este tipo de análisis ayuda a extraer insights cualitativos que complementan las métricas cuantitativas, y es muy útil para mejorar la experiencia del cliente y orientar acciones específicas de mejora."
      ],
      "metadata": {
        "id": "V8xiZv-rCDoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos las palabras del vocabulario\n",
        "palabras = tfidfvectorizer.get_feature_names_out()\n",
        "\n",
        "# Coeficientes del modelo (uno por palabra)\n",
        "coeficientes = model_log_reg.coef_[0]\n",
        "\n",
        "# Creamos un DataFrame para visualizarlo\n",
        "df_coef = pd.DataFrame({'palabra': palabras, 'coeficiente': coeficientes})\n",
        "\n",
        "# Ordenamos por importancia\n",
        "df_coef = df_coef.sort_values(by='coeficiente', ascending=False)\n",
        "\n",
        "# En la primera columna veremos el número \"índice\" de cada palabra según el órden en que fueron procesadas en el modelo.\n",
        "\n",
        "# Mostramos las 10 palabras más asociadas a valoración positiva y negativa\n",
        "print(\"🔼 Palabras más asociadas a reseñas positivas:\")\n",
        "print(df_coef.head(10))\n",
        "\n",
        "print(\"\\n🔽 Palabras más asociadas a reseñas negativas:\")\n",
        "print(df_coef.tail(10))"
      ],
      "metadata": {
        "id": "2bJEOJTHQKb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las palabras con coeficientes positivos más altos, como \"gran\", \"buen\", \"excelente\", \"funciona\" y \"increíble\", están fuertemente asociadas con reseñas positivas, reflejando satisfacción, calidad y buen desempeño del producto o servicio.\n",
        "\n",
        "En contraste, las palabras con coeficientes negativos más fuertes, como \"no\", \"mala\", \"decepcionado\", \"horrible\" y \"terrible\", se asocian claramente con reseñas negativas, indicando insatisfacción, problemas y decepción por parte de los usuarios.\n",
        "\n",
        "Esto muestra que el modelo ha identificado correctamente los términos que expresan opiniones positivas y negativas, lo que facilita la interpretación y el análisis cualitativo del sentimiento en los textos."
      ],
      "metadata": {
        "id": "NoIqfm9UCbRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficar las 10 palabras más positivas y más negativas"
      ],
      "metadata": {
        "id": "6inidvU-R88J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colores pastel suaves (más apagados)\n",
        "color_positivas = '#388e3c'  # verde claro apagado\n",
        "color_negativas = '#e65100'  # rojo claro apagado\n",
        "\n",
        "# Top 10 positivas y negativas\n",
        "top_positivas = df_coef.head(10)\n",
        "top_negativas = df_coef.tail(10).sort_values(by='coeficiente')\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Gráfico de palabras positivas\n",
        "bars1 = ax[0].barh(top_positivas['palabra'], top_positivas['coeficiente'], color=color_positivas)\n",
        "ax[0].set_title('🔼 Palabras asociadas a reseñas positivas', fontsize=14)\n",
        "ax[0].invert_yaxis()\n",
        "ax[0].set_xlabel('Coeficiente', fontsize=12)\n",
        "\n",
        "# Agregar valores al final de las barras (positivas)\n",
        "for bar in bars1:\n",
        "    width = bar.get_width()\n",
        "    ax[0].text(width + 0.01, bar.get_y() + bar.get_height() / 2,\n",
        "               f'{width:.2f}', va='center', fontsize=10)\n",
        "\n",
        "# Gráfico de palabras negativas\n",
        "bars2 = ax[1].barh(top_negativas['palabra'], top_negativas['coeficiente'], color=color_negativas)\n",
        "ax[1].set_title('🔽 Palabras asociadas a reseñas negativas', fontsize=14)\n",
        "ax[1].invert_yaxis()\n",
        "ax[1].set_xlabel('Coeficiente', fontsize=12)\n",
        "\n",
        "# Agregar valores al final de las barras (negativas)\n",
        "for bar in bars2:\n",
        "    width = bar.get_width()\n",
        "    ax[1].text(width - 0.01, bar.get_y() + bar.get_height() / 2,\n",
        "               f'{width:.2f}', va='center', ha='right', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VnNJCbVbRLMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar bigramas y trigramas\n",
        "# Cambiar 'ngrama' a 'palabra' para acceder a la columna correcta\n",
        "df_bi_tri = df_coef[df_coef['palabra'].str.count(' ') >= 2]\n",
        "\n",
        "top_pos_bi_tri = df_bi_tri.sort_values('coeficiente', ascending=False).head(10)\n",
        "top_neg_bi_tri = df_bi_tri.sort_values('coeficiente', ascending=True).head(10)\n",
        "\n",
        "color_positivas = '#388e3c'  # verde oscuro\n",
        "color_negativas = '#e65100'  # naranja oscuro\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
        "\n",
        "axes[0].barh(top_pos_bi_tri['palabra'], top_pos_bi_tri['coeficiente'], color=color_positivas) # Cambiar 'ngrama' a 'palabra'\n",
        "axes[0].invert_yaxis()\n",
        "axes[0].set_title('🔼 Bigrams y Trigrams positivos')\n",
        "axes[0].set_xlabel('Coeficiente')\n",
        "\n",
        "axes[1].barh(top_neg_bi_tri['palabra'], top_neg_bi_tri['coeficiente'], color=color_negativas) # Cambiar 'ngrama' a 'palabra'\n",
        "axes[1].invert_yaxis()\n",
        "axes[1].set_title('🔽 Bigrams y Trigrams negativos')\n",
        "axes[1].set_xlabel('Coeficiente')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VgoYFK0eTcBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 ¿Qué muestran los gráficos?\n",
        "Las palabras con coeficientes positivos son las que más contribuyen a que el modelo prediga una reseña positiva.\n",
        "\n",
        "Las palabras con coeficientes negativos son las que más empujan al modelo hacia una predicción negativa."
      ],
      "metadata": {
        "id": "11CjMM0lR28T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prueba del modelo."
      ],
      "metadata": {
        "id": "bbw6-1oWJYA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se genera un código para probar distintas frases con comentarios genericos con el motivo de evaluar la funcionalidad del modelo de predicción."
      ],
      "metadata": {
        "id": "E7ssFQe3D2jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nueva_reseña = \"no lo recominedo\"  # Reemplaza con la reseña que deseas probar\n",
        "nueva_reseña_tfidf = tfidfvectorizer.transform([nueva_reseña])\n",
        "prediccion = model_log_reg.predict(nueva_reseña_tfidf)\n",
        "# Obtener la probabilidad de la predicción\n",
        "probabilidadpositiva = model_log_reg.predict_proba(nueva_reseña_tfidf)\n",
        "\n",
        "# Obtener la probabilidad en la clase predicha (0 o 1)\n",
        "probabilidad = probabilidadpositiva[0][1]  # Probabilidad de la clase \"positivo\"\n",
        "\n",
        "print(f\"Se predice que la crítica es de caracter {prediccion[0]}\")\n",
        "print(f\" con una probabilidad de que sea positiva de {probabilidad:.2f}\")"
      ],
      "metadata": {
        "id": "W8rk_rn_JdGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando Bag of Words."
      ],
      "metadata": {
        "id": "6nA1NdjV-tYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW convierte un conjunto de documentos en una matriz de ocurrencias de palabras. A diferencia de TF-IDF, que pondera las palabras según su frecuencia e importancia en relación con todo el corpus, BoW solo cuenta cuántas veces aparece una palabra en un documento sin considerar la frecuencia global de la palabra."
      ],
      "metadata": {
        "id": "4N3SqoNl-9SG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ajuste de datos de entrenamiento para BoW."
      ],
      "metadata": {
        "id": "9O22cegICxIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciamos el vectorizador BoW\n",
        "vectorizer_bow = CountVectorizer()\n",
        "\n",
        "# Aplicamos el vectorizador a los comentarios lematizados (ahora en formato string)\n",
        "vector_bow = vectorizer_bow.fit_transform(df['Comentarios_sin_StopWords_str'])\n",
        "\n",
        "# Convertimos la matriz de características en un DataFrame para visualizar\n",
        "bow_df = pd.DataFrame(vector_bow.toarray(), columns=vectorizer_bow.get_feature_names_out())\n",
        "\n",
        "# Obtener los nombres de las características (palabras)\n",
        "features_bow = vectorizer_bow.get_feature_names_out()\n",
        "\n",
        "\n",
        "# Crear un DataFrame con las frecuencias de las palabras\n",
        "df_bow = pd.DataFrame(vector_bow.toarray(), columns=features_bow)"
      ],
      "metadata": {
        "id": "puoPyVHMDFOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar y transformar los datos de entrenamiento\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
        "# Transformar los datos de prueba\n",
        "X_test_bow  = X_test_bow  = vectorizer_bow.transform(X_test)"
      ],
      "metadata": {
        "id": "KuBThnFkC0eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generación y prueba del Modelo con BoW."
      ],
      "metadata": {
        "id": "U-LmgSjwHBdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un modelo de regresión logística\n",
        "# Abajo tenés un código con los parámetros expresados de forma que puedas ir modificandolos\n",
        "model_log_reg_Bow = LogisticRegression() #Instanciamos el modelo\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_log_reg_Bow.fit(X_train_bow, y_train) # Fiteamos, es decir, el modelo aprende a partir de los datos de entrenamiento\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "y_pred_log_reg_Bow = model_log_reg_Bow.predict(X_test_bow) # Predecir"
      ],
      "metadata": {
        "id": "qGBcMOnvHAle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluación del Modelo.\n"
      ],
      "metadata": {
        "id": "PSo23e2IHX2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusión."
      ],
      "metadata": {
        "id": "LxPQYjq3HhL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Matriz de confusión\n",
        "\n",
        "# La Matriz de Confusión es útil para Muestra los aciertos y errores del modelo organizados por clase.\n",
        "\n",
        "cm1 = confusion_matrix(y_test, y_pred_log_reg_Bow)\n",
        "labels = ['Negativo', 'Positivo']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusiónc con BoW')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E9PBCupjHi8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curva ROC AUC."
      ],
      "metadata": {
        "id": "tlGSMfUAH1D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Curva ROC\n",
        "# ROC AUC SCORE evalúa qué tan bien el modelo separa las clases.\n",
        "fpr1, tpr1, _ = roc_curve(y_test, model_log_reg_Bow.decision_function(X_test_bow))\n",
        "roc_auc1 = roc_auc_score(y_test, model_log_reg_Bow.decision_function(X_test_bow))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr1, tpr1, color='darkorange', lw=2, label=f'Área bajo la curva ROC AUC = {roc_auc1:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HONvbjo4HzuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Métricas de Predicción."
      ],
      "metadata": {
        "id": "vW0kWKhaIHmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Métricas\n",
        "# Accuracy:Para medir qué tan bien predice el modelo en datos nuevos (exactitud).\n",
        "# Accuracy mide el porcentaje total de predicciones correctas sobre el total de casos.\n",
        "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
        "# Precision: Para medir el costo de un falso positivo es alto (por ejemplo, recomendar una película mala como buena).\n",
        "# Precision mide qué proporción de las predicciones positivas hechas por el modelo son realmente positivas.\n",
        "precision = precision_score(y_test, y_pred_log_reg)\n",
        "# Recall: Para medir cuántos de los casos positivos reales fueron capturados por el modelo.\n",
        "recall = recall_score(y_test, y_pred_log_reg)\n",
        "# f1 Score: Para medir el promedio armónico entre precisión y recall. Un buen balance si ambas cosas son importantes.\n",
        "f1 = f1_score(y_test, y_pred_log_reg)\n",
        "\n",
        "print(\"Métricas de desempeño del modelo:\")\n",
        "print(f\"Accuracy : {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall   : {recall:.2f}\")\n",
        "print(f\"F1 Score : {f1:.2f}\")"
      ],
      "metadata": {
        "id": "I2xeBzIoIL4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación Cruzada con BoW."
      ],
      "metadata": {
        "id": "NFXHSA1wO2U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline con Bag of Words y Regresión Logística\n",
        "pipeline1 = make_pipeline(\n",
        "    CountVectorizer(max_features=5000),  # Bag of Words\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "# Validación cruzada con 5 particiones\n",
        "scores = cross_val_score(pipeline1, df['Comentario'], df['Valor'], cv=5, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(f\"Precisión media con validación cruzada (BoW): {scores.mean():.3f}\")\n",
        "print(f\"Desviación estándar: {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "vjenYlA_O4eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neuronales."
      ],
      "metadata": {
        "id": "ELvckxoswXK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prueba de Modelo con Keras."
      ],
      "metadata": {
        "id": "8XANfxe7IFA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizar los textos\n",
        "vectorizer_Neuro = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n",
        "X = vectorizer_Neuro.fit_transform(df['Comentarios_sin_StopWords_str']).toarray()"
      ],
      "metadata": {
        "id": "wLwCMh8r2OFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable objetivo\n",
        "y = df['Valor'].values  # Asegurate que sea 0 y 1"
      ],
      "metadata": {
        "id": "L5IRUcaa2oV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir en train y test (estratificado)\n",
        "X_train1, X_val, y_train1, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "Bw9CGsoF2tIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train1.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))  # 1 neurona y activación sigmoid para binario\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',   # función para binaria\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xa26Z1Wq0vAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos el resumen del modelo: esto nos dará detalles sobre cada capa y el número de parámetros entrenables en el modelo.\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IHjJPGEN3Z0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Use X_train1 and y_train1 which were specifically prepared for the neural network\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=100,\n",
        "                    batch_size=10,\n",
        "                    callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "ldJslQYk02Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
        "\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "29EyX-w_3KhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📊 Gráfico de Accuracy y Loss por Época"
      ],
      "metadata": {
        "id": "Hc8eZPsB3fLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Entrenamiento', color='#4caf50')\n",
        "plt.plot(history.history['val_accuracy'], label='Validación', color='#2196f3')\n",
        "plt.title('Precisión (Accuracy) por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Entrenamiento', color='#f57c00')\n",
        "plt.plot(history.history['val_loss'], label='Validación', color='#e53935')\n",
        "plt.title('Pérdida (Loss) por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "reR7qkjk3fpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train1, y_train1, verbose=False)\n",
        "print(\"Precisión Entrenamiento: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, y_val, verbose=False)\n",
        "print(\"Precisión Prueba:  {:.4f}\".format(accuracy))\n",
        ""
      ],
      "metadata": {
        "id": "zLicGea133U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluación del modelo."
      ],
      "metadata": {
        "id": "x7duPNWG31EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**El modelo tiene overfitting**\n",
        "\n",
        "Si hay sobreajuste (overfitting), el modelo aprende demasiado bien los datos de entrenamiento, pero falla al generalizar en los datos nuevos (de validación o test)."
      ],
      "metadata": {
        "id": "LhJgDdfOuPQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📈 ¿Qué es accuracy?\n",
        "Accuracy (precisión) mide el porcentaje de predicciones correctas que hace tu modelo.\n",
        "\n",
        "Se suele graficar en función de las épocas (cada ciclo completo de entrenamiento con todos los datos).\n",
        "\n",
        "✅ Interpretación:\n",
        "Si la accuracy de entrenamiento y validación suben juntas, el modelo está aprendiendo bien.\n",
        "\n",
        "Si la accuracy de entrenamiento sube pero la de validación se estanca o baja, puede estar sobreajustando (overfitting)."
      ],
      "metadata": {
        "id": "25abtumWq56q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📉 ¿Qué es loss?\n",
        "Loss es una medida del error que comete el modelo (por ejemplo, la entropía cruzada en clasificación).\n",
        "\n",
        "El objetivo es minimizar la pérdida durante el entrenamiento.\n",
        "\n",
        "✅ Interpretación:\n",
        "Una loss que disminuye tanto en entrenamiento como validación = buen aprendizaje.\n",
        "\n",
        "Si loss en validación sube mientras la de entrenamiento baja = probable sobreajuste."
      ],
      "metadata": {
        "id": "xR8OJV-trDWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Seleccionar una reseña real del DataFrame\n",
        "indice = 1000  # Cambiá este número si querés ver otra reseña\n",
        "\n",
        "oracion_real = df['Comentario'].iloc[indice]\n",
        "valoracion_real = df['Valor'].iloc[indice]\n",
        "\n",
        "# --- CAMBIO AQUÍ: Usar el mismo TF-IDF Vectorizer usado para entrenar la Red Neuronal ---\n",
        "# Asumiendo que 'vectorizer_Neuro' es el TfidfVectorizer utilizado para crear X_train1 y X_val\n",
        "# Es crucial que sea la *misma* instancia que fue fit_transformed en los datos de entrenamiento\n",
        "# Si no es la misma instancia, o si X_train1/X_val fueron creados con otro vectorizador, ajusta esto.\n",
        "# Basado en el código anterior, parece que vectorizer_Neuro fue usado justo antes de dividir X, y.\n",
        "# Asegúrate de que la celda donde se define vectorizer_Neuro se ejecuta antes que esta.\n",
        "nueva_reseña_vectorizada = vectorizer_Neuro.transform([oracion_real])\n",
        "\n",
        "# Paso 4: Predecir con el modelo\n",
        "# La predicción espera un tensor, y .transform() de TfidfVectorizer devuelve una matriz dispersa.\n",
        "# Necesitamos convertirla a un array denso si el modelo Sequential fue construido para aceptar entradas densas\n",
        "# como lo sugiere el error con Dense(input_shape=(X_train1.shape[1],)).\n",
        "# Asumiendo que X_train1 fue .toarray() después de TF-IDF.\n",
        "nueva_reseña_vectorizada_dense = nueva_reseña_vectorizada.toarray()\n",
        "\n",
        "prediccion = model.predict(nueva_reseña_vectorizada_dense)\n",
        "\n",
        "# Paso 5: Convertir la probabilidad a clase 0 o 1\n",
        "valoracion_predicha = 1 if prediccion[0][0] >= 0.5 else 0\n",
        "\n",
        "# Paso 6: Mostrar resultados\n",
        "print(f\"Reseña: {oracion_real}\")\n",
        "print(f\"Valoración real: {valoracion_real}\")\n",
        "print(f\"Valoración predicha: {valoracion_predicha}\")\n",
        "print(f\"Probabilidad predicha: {prediccion[0][0]:.4f}\")"
      ],
      "metadata": {
        "id": "DVJGqXxwgZtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testeamos con nuevas oraciones\n",
        "\n",
        "# Definir una nueva oración para predecir.\n",
        "nueva_oracion = [\"si es fatal\"]\n",
        "\n",
        "nueva_secuencia_vectorizada = vectorizer_Neuro.transform(nueva_oracion)\n",
        "\n",
        "# Convertir a array denso si el modelo lo espera\n",
        "nueva_secuencia_vectorizada_dense = nueva_secuencia_vectorizada.toarray()\n",
        "\n",
        "\n",
        "# Usar el modelo para predecir la valoración (0 o 1)\n",
        "\n",
        "prediccion = model.predict(nueva_secuencia_vectorizada_dense)\n",
        "\n",
        "print(f\"Predicción: {prediccion[0][0]}\")\n",
        "valoracion = 1 if prediccion[0][0] >= 0.5 else 0\n",
        "print(f\"Valoración predicha: {valoracion}\")"
      ],
      "metadata": {
        "id": "vGXWFPv9_Rnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X ahora contiene un array de secuencias numéricas (en formato tensor o matriz), en las que cada número representa un índice de palabra del vocabulario.\n",
        "# Estas secuencias están ajustadas para tener la misma longitud (max_len=100), con las más largas recortadas y las más cortas rellenadas con ceros.\n",
        "# Visualizamos el tipo de dato que es X\n",
        "print(type(X))\n",
        "\n",
        "print(X)"
      ],
      "metadata": {
        "id": "n5IpwpRgdI9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📦 Tuning con Keras Tuner para clasificación de sentimientos"
      ],
      "metadata": {
        "id": "cKUD3NJddNwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprovechando X_train1, X_val, y_train1, y_val  utilizadas en la primer pureba con Keras, utilizamos las mismas variables paa buscar los mejores hiperparámetros."
      ],
      "metadata": {
        "id": "Q89mG7ewsdaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. PADDEAR"
      ],
      "metadata": {
        "id": "OEUrdoqruYkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Los modelos de tf.keras esperan que todas las secuencias de entrada tengan la misma longitud\n",
        "#para poder agruparlas en una matriz (tensor) y procesarlas por lotes.\n",
        "\n",
        "# Define the maximum length for padding sequences\n",
        "max_len = 1000\n",
        "X_train_pad = pad_sequences(X_train1, maxlen=max_len)\n",
        "X_val_pad = pad_sequences(X_val, maxlen=max_len)"
      ],
      "metadata": {
        "id": "_aklVcYtHMYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 🎯 2. Definir función para el modelo a tunear\n"
      ],
      "metadata": {
        "id": "WTLpPFuNHUAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Embedding(\n",
        "        input_dim=max_words + 1,\n",
        "        output_dim=hp.Choice(\"embedding_dim\", [32, 64, 128]),\n",
        "        input_length=max_len\n",
        "    ))\n",
        "\n",
        "    model.add(Bidirectional(SimpleRNN(\n",
        "        units=hp.Int(\"rnn_units\", min_value=16, max_value=64, step=16)\n",
        "    )))\n",
        "\n",
        "    model.add(Dropout(hp.Choice(\"dropout_rate\", [0.2, 0.3, 0.5])))\n",
        "\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "6Yjso00AHZCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 🔍 3. Inicializar Keras Tuner\n",
        "\n"
      ],
      "metadata": {
        "id": "CurZB9ejHZzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el tamaño del vocabulario basado en el vectorizador TF-IDF\n",
        "# utilizado anteriormente en la sección de Redes Neuronales.\n",
        "# 'vectorizer_Neuro' fue fit_transform en 'df['Comentarios_sin_StopWords_str']'\n",
        "max_words = len(vectorizer_Neuro.vocabulary_)\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory=\"keras_tuner_dir\",\n",
        "    project_name=\"sentiment_rnn_tuning\"\n",
        ")"
      ],
      "metadata": {
        "id": "zeHDY2D8Hdf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 🚀 4. Ejecutar búsqueda"
      ],
      "metadata": {
        "id": "eD5MOpZAHhHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train_pad, y_train1, epochs=5, validation_data=(X_val_pad, y_val))"
      ],
      "metadata": {
        "id": "bSsYH6_RHj5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 🏆 5. Ver los mejores hiperparámetros"
      ],
      "metadata": {
        "id": "XlXgTUIzHmh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "print(\"🔧 Mejores hiperparámetros encontrados:\")\n",
        "for param in best_hp.values:\n",
        "    print(f\"{param}: {best_hp.get(param)}\")"
      ],
      "metadata": {
        "id": "MPWIrQBcHpOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 📈 6. Reentrenar el mejor modelo con más épocas"
      ],
      "metadata": {
        "id": "4RZZfcdxHs2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.hypermodel.build(best_hp)\n",
        "\n",
        "history = best_model.fit(\n",
        "    X_train_pad, y_train1,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "ZUHtZRX1Hv55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 📊 Gráficos de entrenamiento vs validación"
      ],
      "metadata": {
        "id": "7WEHd4zuH4nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer métricas del objeto history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "# Crear figura\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Entrenamiento')\n",
        "plt.plot(epochs_range, val_acc, label='Validación')\n",
        "plt.title('Precisión (accuracy)')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Entrenamiento')\n",
        "plt.plot(epochs_range, val_loss, label='Validación')\n",
        "plt.title('Pérdida (loss)')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_EurnQzRH49Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusiones.**"
      ],
      "metadata": {
        "id": "2Tuqz1acz2js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresion lineal utiliizando TF-IFD\n",
        "\n",
        "🧠 Interpretación general:\n",
        "Tu modelo tiene un rendimiento sólido y equilibrado, con buena capacidad tanto para detectar verdaderos positivos (recall) como para evitar errores en las predicciones positivas (precision). El F1 Score confirma este equilibrio.\n",
        "\n"
      ],
      "metadata": {
        "id": "97FfnuhaBI5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Futuras Lineas.**"
      ],
      "metadata": {
        "id": "-WS2s6UKz5WS"
      }
    }
  ]
}