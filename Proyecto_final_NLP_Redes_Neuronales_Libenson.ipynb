{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5AH8MLYjfwgp",
        "VMtpSPyriRkl",
        "ubaprtVKf88y",
        "D12fghhagRjE",
        "SDKeqnp-gqyc",
        "jk6_6oiZg5Dl",
        "R79sGteNkpVT",
        "_NKoVBUUkw0D",
        "1KM1qtISk-6T",
        "ZhnBUrQTl_BT",
        "ZBXkyZRzmSdj",
        "GNDNz9V5m_EU",
        "GVqmZ6rRoDTd",
        "njpl5RHiosuU",
        "_ryxqKXUo6Ic",
        "lZQPvZfZszkC",
        "NyE94c4JtDWa",
        "vk7QPjtIv4rZ",
        "qD43WO8o5LaU",
        "2189jWXqwNhA",
        "JBBoS9QowA6Z",
        "AvQezV_qx8g4",
        "6nA1NdjV-tYv",
        "PSo23e2IHX2n",
        "ELvckxoswXK5",
        "8XANfxe7IFA5",
        "cKUD3NJddNwC",
        "2Tuqz1acz2js"
      ],
      "authorship_tag": "ABX9TyPY5a1NgrKTq9EWIOJ5OaK+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leucocitokiller/Proyecto-Fina-NLP/blob/main/Proyecto_final_NLP_Redes_Neuronales_Libenson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducci√≥n.**"
      ],
      "metadata": {
        "id": "iynTgO2qzJTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este trabajo pr√°ctico se aborda el an√°lisis y clasificaci√≥n de opiniones de usuarios mediante t√©cnicas de Procesamiento de Lenguaje Natural (NLP) y Machine Learning. Se emplean dos conjuntos de datos distintos, provenientes de plataformas reconocidas: Yelp, que contiene rese√±as de locales de comida, y Amazon, que incluye comentarios sobre productos."
      ],
      "metadata": {
        "id": "4_kaSM_zJAqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objetivos.**"
      ],
      "metadata": {
        "id": "5ZXBeSKazPVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo principal es desarrollar un modelo capaz de identificar autom√°ticamente si un comentario es positivo o negativo, independientemente de la tem√°tica o sector al que pertenezca. Para ello, se aplican diferentes herramientas y t√©cnicas propias del NLP, tales como el tokenizado, lemmatizaci√≥n, entre otras, que permiten transformar los textos en formatos adecuados para su an√°lisis computacional.\n",
        "\n",
        "Posteriormente, se prueba una variedad de modelos de machine learning para evaluar cu√°l es el m√°s efectivo en la clasificaci√≥n de sentimientos en ambos datasets. Esto incluye desde modelos cl√°sicos hasta t√©cnicas m√°s avanzadas, buscando generalizar el aprendizaje para que el modelo pueda detectar la polaridad del comentario m√°s all√° del contexto espec√≠fico.\n",
        "\n",
        "Este enfoque facilita no solo el entendimiento de las opiniones expresadas por los usuarios, sino que tambi√©n permite desarrollar sistemas automatizados de an√°lisis de sentimientos √∫tiles en distintas aplicaciones comerciales y de investigaci√≥n."
      ],
      "metadata": {
        "id": "ZCSpjSaCJLL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Origen de los datos.**"
      ],
      "metadata": {
        "id": "DqzsZE2ozTtx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos pertenecen a una adaptaci√≥n de los comentarios de yelp y amazon y fueron obtenidos del siguiente link de Github:\n",
        "\n",
        "https://github.com/luisFernandoCastellanosG/Machine_learning/blob/master/2-Deep_Learning/PLN/Datasets/DataSetOpiniones.zip\n",
        "\n",
        "Datos del autor:\n",
        "\n",
        "https://github.com/luisFernandoCastellanosG/Machine_learning/blob/master/2-Deep_Learning/PLN/Datasets/readme.md\n",
        "\n"
      ],
      "metadata": {
        "id": "tXedftW6L9Kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Desarrollo.**"
      ],
      "metadata": {
        "id": "UfJPcx_uzjiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importaci√≥n de Librer√≠as.**"
      ],
      "metadata": {
        "id": "5AH8MLYjfwgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "#-----librerias para trabajar NLP\n",
        "!python -m spacy download es_core_news_md\n",
        "import spacy\n",
        "import es_core_news_md\n",
        "#es_core_news_md Medium (modelo mediano):\n",
        "#Es m√°s pesado y m√°s lento que el sm, pero mucho m√°s preciso. Tiene vectores de palabras, entiende mejor el significado de las palabras.\n",
        "\n",
        "#-----instalaci√≥n d librerias para an√°lisis de sentimientos.\n",
        "!pip install spacy spacy-transformers\n",
        "!pip install pysentimiento\n",
        "from pysentimiento import create_analyzer\n",
        "\n",
        "#----librerias para normalizaci√≥n de textos\n",
        "import re\n",
        "from unicodedata import normalize\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#----librerias para graficar y wordcloud.\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#----librer√≠as para trabajar con TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#----libreria para trabajar con BoW.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#----librerias para Machine learning\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
        "#----librerias de Redes Neuronales.\n",
        "# Importamos el Tokenizer para procesar el texto y convertirlo en secuencias num√©ricas\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Importamos la funci√≥n para rellenar las secuencias con ceros y asegurarnos que todas tengan la misma longitud\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Importamos el modelo secuencial de Keras, que permite apilar capas de manera lineal\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "!pip install keras-tuner\n",
        "import keras_tuner as kt\n",
        "# Importamos las capas necesarias:\n",
        "# - Embedding: para convertir √≠ndices de palabras en vectores densos.\n",
        "# - SimpleRNN: una capa recurrente que procesa secuencias de datos.\n",
        "# - Dense: una capa totalmente conectada, utilizada para la salida del modelo.\n",
        "\n"
      ],
      "metadata": {
        "id": "64jaT-pwfyzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Procesamiento de la Fuente de Datos.**"
      ],
      "metadata": {
        "id": "VMtpSPyriRkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexi√≥n con la fuente de datos.\n"
      ],
      "metadata": {
        "id": "ubaprtVKf88y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se cargan dos dataset desde Github que contienen comentarios sobre celulares (Amanzon) y servicio de restaurantes (Yelp). Ambos dataset se unifican para tener un mayor volumen de datos para analizar.\n",
        "\n",
        "Los mismos estan compuestos por dos columnas, una con los comentarios de cada usario registrado y otra con el valor asignado a ese comentario.\n",
        "Si el comentario tiene un valor 1 se lo considera positivo y si tiene valor 2 como negativo."
      ],
      "metadata": {
        "id": "KU4pkuDmqq--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario con las fuentes y sus URLs\n",
        "filepath_dict = {\n",
        "    'yelp': 'https://raw.githubusercontent.com/Leucocitokiller/Proyecto-Fina-NLP/main/yelp_comentarios.csv',\n",
        "    'amazon': 'https://raw.githubusercontent.com/Leucocitokiller/Proyecto-Fina-NLP/main/amazon_cells_comentarios.csv'\n",
        "\n",
        "}\n",
        "\n",
        "df_list = []\n",
        "for source, filepath in filepath_dict.items():\n",
        "    df = pd.read_csv(filepath, names=['Comentario', 'Valor'], sep=';', encoding='latin-1')\n",
        "    df['Origen'] = source  # se agrega una nueva columna para saber si los comentarios son de Yelp o Amazon.\n",
        "    df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list)\n",
        "df.head(1100)"
      ],
      "metadata": {
        "id": "QA3En5EYgAtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizaci√≥n de la Fuente de datos.\n"
      ],
      "metadata": {
        "id": "Eagv-jaJgM_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eliminaci√≥n de signos de puntuaci√≥n."
      ],
      "metadata": {
        "id": "D12fghhagRjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n de funci√≥n para eliminar los signos de puntuaci√≥n utilizando re, pero considerando no borrar las vocales con acento.\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    # Normaliza el texto a NFKD para separar letras y sus tildes\n",
        "    text = unicodedata.normalize('NFKD', text)\n",
        "    # Elimina los caracteres diacr√≠ticos (como las tildes)\n",
        "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
        "    # Elimina todo lo que no sea letras, n√∫meros o espacios\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Aplicar la funci√≥n a la columna 'review_lower'\n",
        "df['Comentarios'] = df['Comentario'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "TlTn8VuygQxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ez4O1zkbhB2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reducir a min√∫sculas el texto."
      ],
      "metadata": {
        "id": "SDKeqnp-gqyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column 'Comentarios_lower' with lowercase values from 'Comentario'\n",
        "df['Comentarios_lower'] = df['Comentarios'].str.lower()"
      ],
      "metadata": {
        "id": "ExcMpIx7gw-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_O0hOspchMl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convertir a n√∫mero la columna Valor para su postprocesamiento."
      ],
      "metadata": {
        "id": "jk6_6oiZg5Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos la columna rating a valor num√©rico\n",
        "df['Valor'] = pd.to_numeric(df['Valor'], errors='coerce')"
      ],
      "metadata": {
        "id": "a_urHIsIg7Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Valor']"
      ],
      "metadata": {
        "id": "yUwGYj_jhIud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP**"
      ],
      "metadata": {
        "id": "39XV91NgkM9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Procesamiento."
      ],
      "metadata": {
        "id": "R79sGteNkpVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generaci√≥n del objeto de SPacy para utilizar en el procesamiento del texto en espa√±ol."
      ],
      "metadata": {
        "id": "_NKoVBUUkw0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de aplicar t√©cnicas de an√°lisis de sentimiento, se debe realizar un preprocesamiento del texto que prepare los datos para ser interpretados por modelos de NLP.\n",
        "En este paso, se lleva a cabo la generaci√≥n del objeto de spaCy para trabajar con el idioma espa√±ol, lo cual permite aprovechar herramientas ling√º√≠sticas como la tokenizaci√≥n, lematizaci√≥n"
      ],
      "metadata": {
        "id": "mJtkLU3WP1cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = es_core_news_md.load()"
      ],
      "metadata": {
        "id": "aiW_XvTOkm2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convertir texto a min√∫sculas y Tokenizaci√≥n."
      ],
      "metadata": {
        "id": "1KM1qtISk-6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una de las primeras transformaciones aplicadas es la conversi√≥n del texto a min√∫sculas, lo que ayuda a normalizar las palabras y evitar que el modelo interprete como diferentes aquellas que solo var√≠an en el uso de may√∫sculas (por ejemplo, \"Bueno\" y \"bueno\"). A continuaci√≥n, se realiza la tokenizaci√≥n, que consiste en dividir el texto en unidades m√≠nimas llamadas tokens (como palabras, signos de puntuaci√≥n o n√∫meros), facilitando el an√°lisis posterior del lenguaje."
      ],
      "metadata": {
        "id": "Qm49X2mKP_L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Comentarios_tokenizados'] = df['Comentarios_lower'].apply(lambda text: nlp(text))\n",
        "df[['Comentarios_lower','Comentarios_tokenizados']].head()"
      ],
      "metadata": {
        "id": "uVF3ar5olBDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remoci√≥n de StopWords"
      ],
      "metadata": {
        "id": "ZhnBUrQTl_BT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante la eliminaci√≥n de stopwords, que son palabras vac√≠as o de bajo contenido sem√°ntico (como ‚Äúel‚Äù, ‚Äúla‚Äù, ‚Äúy‚Äù, ‚Äúde‚Äù), se identific√≥ que en algunos casos su remoci√≥n pod√≠a afectar negativamente el sentido original de las frases. Esto es particularmente relevante en rese√±as donde expresiones comunes dependen de ciertas palabras funcionales para conservar su significado completo.\n",
        "\n",
        "Por esta raz√≥n, fue necesario generar un listado personalizado de palabras que deb√≠an conservarse.\n",
        "\n",
        "Esto permiti√≥ preservar la coherencia y contexto de los comentarios, evitando que el modelo perdiera informaci√≥n clave para la detecci√≥n del sentimiento."
      ],
      "metadata": {
        "id": "oMmYeo9lQZbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de palabras que NO queremos eliminar (tienen carga emocional)\n",
        "palabras_sentimiento = {\n",
        "    # Positivas\n",
        "    \"bueno\", \"buena\",\"si\",\"buen√≠simo\", \"excelentes\", \"excelente\", \"genial\", \"maravilloso\", \"maravilla\", \"fant√°stico\", \"fabuloso\", \"incre√≠ble\",\n",
        "    \"perfecto\", \"perfecta\", \"agradable\", \"satisfecho\", \"satisfecha\", \"contento\", \"contenta\", \"encantado\", \"encantada\",\n",
        "    \"amable\", \"simp√°tico\", \"simp√°tica\", \"r√°pido\", \"r√°pida\", \"c√≥modo\", \"c√≥moda\", \"eficaz\", \"eficiente\", \"f√°cil\",\n",
        "    \"recomendable\", \"ideal\", \"espectacular\", \"feliz\", \"brillante\", \"cumpli√≥\", \"cumple\", \"funciona\", \"funciona bien\",\n",
        "    \"inmejorable\", \"confiable\", \"duradero\", \"cumplidor\", \"seguro\", \"preciso\", \"elegante\", \"atento\", \"responsable\",\n",
        "    \"acertado\", \"destacado\", \"excepcional\", \"impecable\", \"sensacional\", \"√∫til\", \"accesible\", \"econ√≥mico\", \"funcional\",\n",
        "    \"intuitivo\", \"conveniente\", \"hermoso\", \"linda\", \"precioso\", \"excelente calidad\", \"vale la pena\",\n",
        "\n",
        "    # Negativas\n",
        "    \"malo\",\"no\", \"mala\", \"mal\", \"p√©simo\", \"p√©sima\",\"nunca\", \"horrible\", \"fatal\", \"insoportable\", \"lento\", \"lenta\", \"inc√≥modo\", \"inc√≥moda\",\n",
        "    \"decepcionante\", \"decepcionado\", \"decepcionada\", \"sucio\", \"sucia\", \"caro\", \"cara\", \"in√∫til\", \"deficiente\", \"desagradable\",\n",
        "    \"complicado\", \"problem√°tico\", \"estafa\", \"enga√±ado\", \"enga√±ada\", \"roto\", \"rota\", \"desastroso\", \"error\", \"errores\",\n",
        "    \"retraso\", \"tardanza\", \"fr√°gil\", \"inestable\", \"poco fiable\", \"nunca m√°s\", \"no volver√©\", \"no recomiendo\", \"no sirve\",\n",
        "    \"no funciona\", \"arruinado\", \"fall√≥\", \"fallando\", \"demora\", \"p√©sima atenci√≥n\", \"servicio malo\", \"mala calidad\", \"molesto\",\n",
        "    \"defecto\", \"problemas\", \"fallas\", \"sin sentido\", \"basura\", \"p√©rdida de dinero\", \"decepci√≥n\"\n",
        "}\n",
        "\n",
        "# Actualizamos spaCy para que NO considere esas palabras como stopwords\n",
        "for palabra in palabras_sentimiento:\n",
        "    lex = nlp.vocab[palabra]\n",
        "    lex.is_stop = False\n",
        "\n",
        "def parse_and_remove_stopwords(doc):\n",
        "    \"\"\"\n",
        "    Remueve las stopwords de un objeto spaCy Doc.\n",
        "    \"\"\"\n",
        "    # Filtrar stopwords y obtener los tokens como texto\n",
        "    tokens_filtrados = [token.text for token in doc if not token.is_stop]\n",
        "    return tokens_filtrados\n",
        "\n",
        "# Aplicar la funci√≥n al DataFrame\n",
        "df['Comentarios_sin_StopWords'] = df['Comentarios_tokenizados'].apply(parse_and_remove_stopwords)\n",
        "\n",
        "df[['Comentarios_tokenizados','Comentarios_sin_StopWords']].head()"
      ],
      "metadata": {
        "id": "2_cr__EqmG4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lematizado."
      ],
      "metadata": {
        "id": "ZBXkyZRzmSdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se procede a aplicar la lematizaci√≥n, una t√©cnica que permite reducir cada palabra a su forma base o \"lema\". Por ejemplo, palabras como ‚Äúcomprando‚Äù, ‚Äúcompr√©‚Äù o ‚Äúcomprar√≠an‚Äù se transforman en ‚Äúcomprar‚Äù. Esto es esencial para evitar la dispersi√≥n sem√°ntica y lograr que el modelo reconozca distintas variantes de una palabra como una misma entidad."
      ],
      "metadata": {
        "id": "sYr3W0kMQwwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lematizar_sin_stopwords(doc):\n",
        "    \"\"\"\n",
        "    Devuelve una lista de lemas excluyendo las stopwords.\n",
        "\n",
        "    Par√°metro:\n",
        "    - doc: objeto spaCy Doc\n",
        "\n",
        "    Retorna:\n",
        "    - Lista de lemas (str) sin stopwords\n",
        "    \"\"\"\n",
        "    return [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
        "\n",
        "# Aplicar la funci√≥n y guardar el resultado en una nueva columna\n",
        "df['Comentarios_lema'] = df['Comentarios_tokenizados'].apply(lematizar_sin_stopwords)\n",
        "\n",
        "df[['Comentarios_tokenizados','Comentarios_lema']].head(20)"
      ],
      "metadata": {
        "id": "DsRRS29ImVnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesamiento"
      ],
      "metadata": {
        "id": "9bW_hSCRm02p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conteo de Palabras mas comunes."
      ],
      "metadata": {
        "id": "GNDNz9V5m_EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como parte del an√°lisis exploratorio, se realiz√≥ un conteo de las palabras m√°s frecuentes dentro de los comentarios.\n",
        "Esta etapa permite identificar los t√©rminos que predominan en el lenguaje utilizado por los usuarios y detectar patrones o temas recurrentes en las opiniones.\n",
        "\n",
        "Para un an√°lisis m√°s detallado, el conteo se dividi√≥ entre los comentarios de Yelp y Amazon, con el fin de comparar el vocabulario caracter√≠stico de cada plataforma. Mientras Yelp tiende a centrarse en experiencias relacionadas con servicios (como restaurantes o locales comerciales), Amazon refleja opiniones sobre productos, lo cual se evidencia en las diferencias l√©xicas observadas entre ambos conjuntos de datos."
      ],
      "metadata": {
        "id": "7xH0ak7NRHlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graficar_palabras_comunes(df, origen, top_n=10):\n",
        "    # Filtrar y aplanar los lemas\n",
        "    lemas = [lema for lemas in df[df['Origen'] == origen]['Comentarios_lema'] for lema in lemas]\n",
        "    conteo = Counter(lemas).most_common(top_n)\n",
        "\n",
        "    # Separar palabras y frecuencias\n",
        "    palabras, frecuencias = zip(*conteo)\n",
        "\n",
        "    # Crear gr√°fico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(palabras, frecuencias, color='skyblue')\n",
        "    plt.xlabel('Frecuencia')\n",
        "    plt.title(f'Top {top_n} Palabras M√°s Comunes - {origen.capitalize()}')\n",
        "    plt.gca().invert_yaxis()  # Poner la palabra m√°s com√∫n arriba\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Graficar para Yelp\n",
        "graficar_palabras_comunes(df, 'yelp')\n",
        "\n",
        "# Graficar para Amazon\n",
        "graficar_palabras_comunes(df, 'amazon')"
      ],
      "metadata": {
        "id": "cHPKUNjjoJQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conteo de bigramas m√°s comunes."
      ],
      "metadata": {
        "id": "GVqmZ6rRoDTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adem√°s del an√°lisis de palabras individuales, se llev√≥ a cabo un conteo de bigramas (pares de palabras consecutivas) con el objetivo de capturar expresiones m√°s completas y contextuales utilizadas por los usuarios en sus comentarios. A diferencia del an√°lisis unigram (una sola palabra), los bigramas permiten identificar frases frecuentes que pueden tener un valor sem√°ntico m√°s claro, como \"muy bueno\", \"no funciona\", \"excelente producto\", entre otros."
      ],
      "metadata": {
        "id": "wDVQ4InbRZ7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from itertools import tee\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generar_bigramas(lista):\n",
        "    \"\"\"Devuelve bigramas como tuplas a partir de una lista de palabras\"\"\"\n",
        "    a, b = tee(lista)\n",
        "    next(b, None)\n",
        "    return list(zip(a, b))\n",
        "\n",
        "def graficar_bigramas_comunes(df, origen, top_n=10):\n",
        "    # Filtrar solo los comentarios del origen y generar bigramas\n",
        "    bigramas = [\n",
        "        bigrama\n",
        "        for lemas in df[df['Origen'] == origen]['Comentarios_lema']\n",
        "        for bigrama in generar_bigramas(lemas)\n",
        "    ]\n",
        "\n",
        "    conteo = Counter(bigramas).most_common(top_n)\n",
        "\n",
        "    # Convertir tuplas de bigramas a string para graficar\n",
        "    etiquetas = [' '.join(b) for b, _ in conteo]\n",
        "    frecuencias = [f for _, f in conteo]\n",
        "\n",
        "    # Crear gr√°fico\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(etiquetas, frecuencias, color='mediumseagreen')\n",
        "    plt.xlabel('Frecuencia')\n",
        "    plt.title(f'Top {top_n} Bigramas M√°s Comunes - {origen.capitalize()}')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejemplo de uso\n",
        "graficar_bigramas_comunes(df, 'yelp')\n",
        "graficar_bigramas_comunes(df, 'amazon')\n"
      ],
      "metadata": {
        "id": "_B3v3nOknL2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WordClouds"
      ],
      "metadata": {
        "id": "tn6x4GaEoYRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para complementar el an√°lisis exploratorio, se generaron nubes de palabras que representan gr√°ficamente la frecuencia de aparici√≥n de t√©rminos en los comentarios. Este tipo de visualizaci√≥n permite identificar r√°pidamente las palabras y frases m√°s utilizadas por los usuarios, otorgando una vista intuitiva del contenido predominante en cada dataset.\n",
        "\n",
        "Se realizaron dos tipos de word clouds:\n",
        "\n",
        "Una para monogramas, es decir, palabras individuales.\n",
        "\n",
        "Otra para bigramas, que agrupa las dos palabras consecutivas m√°s frecuentes.\n",
        "\n",
        "Ambos casos compara a Yelp y Amazon."
      ],
      "metadata": {
        "id": "JJ__43PrRsvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud Yelp."
      ],
      "metadata": {
        "id": "VCXSZ4glokBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el DataFrame\n",
        "df_yelp = df[df['Origen'] == 'yelp']\n",
        "\n",
        "# Unir todos los lemas en un solo string (comentarios lematizados ya est√°n en listas)\n",
        "texto_yelp = ' '.join([' '.join(lemas) for lemas in df_yelp['Comentarios_lema']])\n",
        "\n",
        "# Crear la nube de palabras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto_yelp)\n",
        "\n",
        "# Mostrar la nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nube de Palabras - Comentarios de Yelp\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UXGDKZCaocLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud Amazon."
      ],
      "metadata": {
        "id": "njpl5RHiosuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el DataFrame\n",
        "df_amazon = df[df['Origen'] == 'amazon']\n",
        "\n",
        "# Unir todos los lemas en un solo string (comentarios lematizados ya est√°n en listas)\n",
        "texto_amazon = ' '.join([' '.join(lemas) for lemas in df_amazon['Comentarios_lema']])\n",
        "\n",
        "# Crear la nube de palabras\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto_amazon)\n",
        "\n",
        "# Mostrar la nube\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nube de Palabras - Comentarios de Yelp\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PHfxMdccou0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WordCloud + Bigramas."
      ],
      "metadata": {
        "id": "_ryxqKXUo6Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generar_bigramas_spacy(df, origen, top_n=50):\n",
        "    \"\"\"\n",
        "    Genera bigramas usando spaCy a partir de la columna 'Comentarios_Lema', sin stopwords.\n",
        "    Luego genera una nube de palabras.\n",
        "    \"\"\"\n",
        "    # Filtrar los comentarios por 'origen' (por ejemplo, 'yelp' o 'amazon')\n",
        "    comentarios = df[df['Origen'] == origen]['Comentarios_sin_StopWords']\n",
        "\n",
        "    # Generar bigramas\n",
        "    bigramas = []\n",
        "    for comentario in comentarios:\n",
        "        # Crear un Doc de spaCy a partir de la lista de lemas (de la columna 'Comentarios_Lema')\n",
        "        doc = nlp(' '.join(comentario))  # Unimos la lista de lemas y lo procesamos con spaCy\n",
        "        # Extraer bigramas\n",
        "        for i in range(len(doc) - 1):\n",
        "            if not doc[i].is_stop and not doc[i+1].is_stop:  # Asegurarse de que no sean stopwords\n",
        "                bigramas.append((doc[i].lemma_, doc[i+1].lemma_))\n",
        "\n",
        "    # Contar los bigramas m√°s comunes\n",
        "    conteo_bigramas = Counter(bigramas).most_common(top_n)\n",
        "\n",
        "    # Convertir los bigramas a formato texto \"palabra1 palabra2\"\n",
        "    bigramas_texto = {' '.join(bigrama): freq for bigrama, freq in conteo_bigramas}\n",
        "\n",
        "    # Generar la nube de palabras de los bigramas\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(bigramas_texto)\n",
        "\n",
        "    # Mostrar la nube\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Word Cloud de Bigramas - {origen.capitalize()}\")\n",
        "    plt.show()\n",
        "\n",
        "# Generar la nube de bigramas para Yelp y Amazon\n",
        "generar_bigramas_spacy(df, 'yelp')\n",
        "generar_bigramas_spacy(df, 'amazon')"
      ],
      "metadata": {
        "id": "qW644mkPo8qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###üöÄ An√°lisis de sentimiento en espa√±ol con pysentimiento"
      ],
      "metadata": {
        "id": "3h4HlXQzpWl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez preprocesados los textos, se aplic√≥ un modelo de an√°lisis de sentimiento espec√≠ficamente entrenado para el idioma espa√±ol utilizando la librer√≠a pysentimiento.\n",
        "\n",
        "pysentimiento permite detectar si un comentario es positivo, negativo o neutral, lo cual resulta fundamental para evaluar la percepci√≥n general de los usuarios sobre un producto o servicio. A diferencia de otros enfoques m√°s simples, este modelo considera la estructura gramatical y el significado global de la oraci√≥n, lo que mejora notablemente la precisi√≥n, especialmente en expresiones ambiguas o sarc√°sticas."
      ],
      "metadata": {
        "id": "IxdlTr29SR_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear analizador de sentimientos\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "\n",
        "# Aplicar a una columna de texto\n",
        "df['Sentimiento'] = df['Comentario'].apply(lambda x: analyzer.predict(x).output)\n",
        "# Sentimiento solo guarda lo predicho (POS, NEU o NEG)\n",
        "\n",
        "df['Probabilidad'] = df['Comentario'].apply(lambda x: analyzer.predict(x).probas)\n",
        "#Ese diccionario contiene la probabilidad de cada clase: positivo, neutro, negativo Ejemplo: {'POS': 0.84, 'NEU': 0.10, 'NEG': 0.06}."
      ],
      "metadata": {
        "id": "r5feGF2Gpias"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üìä  Gr√°fico de barras de frecuencia de sentimientos"
      ],
      "metadata": {
        "id": "lZQPvZfZszkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df, x='Sentimiento', order=['POS', 'NEU', 'NEG'], palette='pastel')\n",
        "plt.title('Distribuci√≥n de Sentimientos totales entre Yelp y Amazon')\n",
        "plt.xlabel('Sentimiento')\n",
        "plt.ylabel('Cantidad de Comentarios')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ddaD7cous3SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribuci√≥n de los sentimientos."
      ],
      "metadata": {
        "id": "NyE94c4JtDWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentimiento'].value_counts().plot.pie(\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    labels=['Positivo', 'Neutro', 'Negativo'],\n",
        "    colors=['lightgreen', 'lightblue', 'salmon']\n",
        ")\n",
        "plt.title('Distribuci√≥n porcentual de Sentimientos')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dI2qGwfVs837"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### An√°lisis de Confianza para filtrar comentarios con baja certeza"
      ],
      "metadata": {
        "id": "N9Ehqc_htP8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego de aplicar el modelo de an√°lisis de sentimiento con pysentimiento, se incorpor√≥ una etapa adicional para evaluar la confianza de las predicciones. Este an√°lisis se basa en las probabilidades asignadas a cada clase (positivo, negativo o neutral), lo que permite identificar qu√© tan seguro est√° el modelo respecto a cada clasificaci√≥n realizada.\n",
        "\n",
        "Con esta informaci√≥n se implement√≥ un filtro de confianza, excluyendo o marcando aquellos comentarios cuya predicci√≥n tiene baja certeza (por ejemplo, menor al 60%). Esta estrategia ayuda a reducir errores en el an√°lisis general, ya que evita tomar decisiones basadas en clasificaciones inciertas o ambiguas.\n",
        "\n",
        "Adem√°s, el an√°lisis de confianza permite estudiar qu√© tipos de comentarios generan m√°s dudas en el modelo, lo que puede ser √∫til para mejorar el preprocesamiento, ajustar umbrales, o incluso etiquetar manualmente ciertos casos en futuras iteraciones del modelo."
      ],
      "metadata": {
        "id": "vqG1qPzUSzN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# M√°xima probabilidad (nivel de certeza del modelo)\n",
        "df['Confianza'] = df['Probabilidad'].apply(lambda x: max(x.values()))  # En este caso, de la lista {'POS': 0.84, 'NEU': 0.10, 'NEG': 0.06} s√≥lo guarda 0.84 que es el valor mayor\n",
        "\n",
        "# Filtrar comentarios cuya confianza sea menor a 0.6\n",
        "comentarios_baja_confianza = df[df['Confianza'] < 0.6]\n",
        "comentarios_alta_confianza = df[df['Confianza'] >= 0.6]\n",
        "# Ver los primeros resultados\n",
        "#comentarios_baja_confianza[['Comentarios', 'Sentimiento', 'Confianza']]"
      ],
      "metadata": {
        "id": "cp_TPbgYtUPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribuci√≥n de los comentarios filtrados."
      ],
      "metadata": {
        "id": "Np0Wbkh-t9ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Confianza'] >= 0.6]['Sentimiento'].value_counts().plot.pie(\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    labels=['Positivo', 'Neutro', 'Negativo'],\n",
        "    colors=['lightgreen', 'lightblue', 'salmon']\n",
        ")\n",
        "plt.title('Distribuci√≥n porcentual de Sentimientos con alta confianza')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DKGk25nltsFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distribuci√≥n de la Confianza de los comentarios."
      ],
      "metadata": {
        "id": "8UwgeOBbuhWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data=df, x='Confianza', bins=20, kde=True, color='skyblue')\n",
        "plt.axvline(0.6, color='red', linestyle='--', label='Umbral 0.6')\n",
        "plt.title('Distribuci√≥n de Confianza del Sentimiento')\n",
        "plt.xlabel('Confianza')\n",
        "plt.ylabel('Cantidad de Comentarios')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W1mX2p80uabR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comentarios_baja_confianza[['Comentario', 'Sentimiento', 'Confianza', 'Probabilidad']].sort_values(by='Confianza').head(20)\n"
      ],
      "metadata": {
        "id": "4tHWg2UiT5Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pruebas de Modelos de Machine Learning.**"
      ],
      "metadata": {
        "id": "vk7QPjtIv4rZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este punto, se realizar√° un an√°lisis de texto con el objetivo de predecir una variable num√©rica que nos indica positvo (para 1) y negativo (para 0), a partir de opiniones o rese√±as escritas por usuarios.\n",
        "\n",
        "\n",
        "Para convertir los textos en datos num√©ricos que puedan ser procesados por modelos de machine learning, seutilizaran dos t√©cnicas de representaci√≥n de texto:TF-IDF (Term Frequency-Inverse Document Frequency) y Bag of Words (BoW).\n",
        "\n",
        "\n",
        "TF-IDF pondera la frecuencia de las palabras en cada documento ajust√°ndola seg√∫n su frecuencia inversa en todo el corpus, dando mayor peso a t√©rminos distintivos y reduciendo la influencia de palabras comunes.\n",
        "\n",
        "Bag of Words representa cada documento como un vector que indica la frecuencia de cada palabra, sin considerar el orden ni la relevancia contextual.\n",
        "\n",
        "Estos vectores van a ser utilizados como entrada para un modelo de regresi√≥n log√≠stica, que permitir√° predecir la variable objetivo asociada a cada texto, en este caso si los comentarios son positivos o negativos.\n",
        "\n",
        "Adicionalmente, se incorporar√° un modelo de deep learning utilizando la biblioteca Keras, que aprvechando redes neuronales para capturar patrones m√°s complejos en los textos, incluyendo relaciones contextuales y secuenciales entre palabras que no pueden ser detectadas por las representaciones tradicionales.\n",
        "\n",
        "Se entrenar√°n y evaluar√°n los tres modelos ‚Äîregresi√≥n lineal con Bag of Words, regresi√≥n lineal con TF-IDF y red neuronal profunda con Keras‚Äî para comparar su desempe√±o predictivo.\n",
        "\n",
        "La evaluaci√≥n incluir√° m√©tricas adecuadas para regresi√≥n y an√°lisis de generalizaci√≥n, con el fin de identificar cu√°l enfoque es m√°s efectivo para este problema espec√≠fico.\n",
        "\n",
        "Este an√°lisis permitir√° no solo comparar t√©cnicas cl√°sicas y modernas de procesamiento de texto, sino tambi√©n obtener insights sobre la relevancia y el impacto de las palabras y estructuras en la predicci√≥n, mejorando la comprensi√≥n del comportamiento del modelo y la calidad de las predicciones."
      ],
      "metadata": {
        "id": "OLYy9hwkE4Ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisi√≥n de datos de entrenamiento y prueba."
      ],
      "metadata": {
        "id": "qD43WO8o5LaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['Comentario'], df['Valor'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "jkK0y7oy5Z_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresi√≥n Log√≠stica."
      ],
      "metadata": {
        "id": "2189jWXqwNhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando TF-IFD."
      ],
      "metadata": {
        "id": "JBBoS9QowA6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (Term Frequency - Inverse Document Frequency) es una t√©cnica de procesamiento de texto utilizada para evaluar la importancia de una palabra dentro de un conjunto de documentos. Se basa en dos conceptos:\n",
        "\n",
        "TF (Frecuencia de T√©rmino): Mide cu√°ntas veces aparece un t√©rmino en un documento espec√≠fico, comparado con el n√∫mero total de t√©rminos en ese documento. Esto ayuda a capturar cu√°n relevante es una palabra dentro de un documento en particular.\n",
        "\n",
        "IDF (Frecuencia Inversa de Documentos): Mide la importancia de una palabra dentro de un conjunto de documentos. Si una palabra aparece en muchos documentos, tiene menos valor. La f√≥rmula es:\n",
        "\n",
        "Esto ayuda a reducir el peso de las palabras que aparecen frecuentemente en todos los documentos (como \"el\", \"y\", \"de\"), ya que no agregan mucha informaci√≥n.\n",
        "\n",
        "As√≠, la importancia de un t√©rmino en un documento depende tanto de su frecuencia en ese documento como de cu√°n com√∫n es en todo el conjunto de documentos."
      ],
      "metadata": {
        "id": "Z5Qu0o3RwyoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### C√°lculo de TF-IDF con TfidVetorizer y analisis de n-gramas."
      ],
      "metadata": {
        "id": "AvQezV_qx8g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # TFIDF espera trabajar con strings y  no listas, por lo que se procede a crear una nueva columna con los datos tokenizados en formato str.\n",
        "df['Comentarios_sin_StopWords_str'] = df['Comentarios_sin_StopWords'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Crear el vectorizador\n",
        "tfidfvectorizer = TfidfVectorizer(ngram_range=(1,5))\n",
        "#inlcuyo bigramas y trigramas para que le de contexto a los comentarios. Esto me permite ver un \"No conforme\" y no solamente le \"No\" y el \"Conforme\" por separado.\n",
        "\n",
        "# Ajustar y transformar\n",
        "tfidf_matrix = tfidfvectorizer.fit_transform(df['Comentarios_sin_StopWords_str'])\n",
        "\n",
        "# Obtener los t√©rminos\n",
        "features = tfidfvectorizer.get_feature_names_out()\n",
        "\n",
        "# Convertir la matriz a DataFrame\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=features)\n",
        "\n",
        "# Sumar TF-IDF por columna\n",
        "tfidf_scores = df_tfidf.sum().sort_values(ascending=False)\n",
        "\n",
        "# Mostrar top 10\n",
        "print(\"üîù Top 10 n-gramas por score TF-IDF:\")\n",
        "print(tfidf_scores.head(10).round(3))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yOA1KulbyJG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame auxiliar con el tipo de n-grama\n",
        "df_scores = pd.DataFrame({\n",
        "    'ngram': tfidf_scores.index,\n",
        "    'score': tfidf_scores.values,\n",
        "    'tipo': tfidf_scores.index.to_series().apply(lambda x: f'{len(x.split())}-grama')\n",
        "})\n",
        "\n",
        "# Ver los 5 m√°s importantes por tipo\n",
        "top_n = 5\n",
        "for tipo in ['1-grama', '2-grama', '3-grama']:\n",
        "    print(f\"\\nüîù Top {top_n} {tipo}s:\")\n",
        "    print(df_scores[df_scores['tipo'] == tipo].head(top_n).to_string(index=False))"
      ],
      "metadata": {
        "id": "8TncVynMzZlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El an√°lisis de los n-gramas (1, 2 y 3 palabras) revela una fuerte tendencia negativa en los comentarios analizados.\n",
        "\n",
        "Esto se evidencia principalmente por:\n",
        "\n",
        "La presencia dominante de la palabra \"no\" como unigram (1-grama) m√°s relevante, indicando una alta frecuencia de negaciones.\n",
        "\n",
        "Los bigramas y trigramas refuerzan esta tendencia negativa, con frases como \"no volveremos\", \"no volvere\", \"no funciona\", \"no recomendaria\", \"no vale pena\" y \"no compre producto\", todas las cuales reflejan insatisfacci√≥n o malas experiencias.\n",
        "\n",
        "Aun as√≠, hay menciones positivas como \"buena comida servicio\", pero estas son menos frecuentes o tienen menor peso que las negativas."
      ],
      "metadata": {
        "id": "b4VhVp3p41Q0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ajuste de datos de Entrenamiento."
      ],
      "metadata": {
        "id": "jGzhxUtp6DAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajustamos el vectorizador TF-IDF con los datos de entrenamiento y test  transformando esos datos en una matriz num√©rica."
      ],
      "metadata": {
        "id": "OREs2HSJ-9jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar y transformar los datos de entrenamiento\n",
        "X_train_tfidf = tfidfvectorizer.fit_transform(X_train)\n",
        "# Transformar los datos de prueba\n",
        "X_test_tfidf = tfidfvectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "C9X3Y3tX6JQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generaci√≥n y prueba de modelo Regresi√≥n Log√≠stica."
      ],
      "metadata": {
        "id": "4zXnyKl47GSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un modelo de regresi√≥n log√≠stica\n",
        "# Abajo ten√©s un c√≥digo con los par√°metros expresados de forma que puedas ir modificandolos\n",
        "model_log_reg = LogisticRegression() #Instanciamos el modelo\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_log_reg.fit(X_train_tfidf, y_train) # Fiteamos, es decir, el modelo aprende a partir de los datos de entrenamiento\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "y_pred_log_reg = model_log_reg.predict(X_test_tfidf) # Predecir"
      ],
      "metadata": {
        "id": "lmGzeGnU7NlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluaci√≥n del Modelo."
      ],
      "metadata": {
        "id": "BKMGMFHX8OKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusi√≥n."
      ],
      "metadata": {
        "id": "i8zfSea79_Bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Matriz de confusi√≥n\n",
        "\n",
        "# La Matriz de Confusi√≥n es √∫til para Muestra los aciertos y errores del modelo organizados por clase.\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_log_reg)\n",
        "labels = ['Negativo', 'Positivo']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SZu-1myh8k3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä Interpretaci√≥n de los resultados:\n",
        "TP (Verdaderos Positivos) = 148: Casos positivos correctamente clasificados como positivos.\n",
        "\n",
        "TN (Verdaderos Negativos) = 181: Casos negativos correctamente clasificados como negativos.\n",
        "\n",
        "FP (Falsos Positivos) = 28: Casos negativos mal clasificados como positivos.\n",
        "\n",
        "FN (Falsos Negativos) = 33: Casos positivos mal clasificados como negativos."
      ],
      "metadata": {
        "id": "r9XnpcfN_efX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La matriz de confusi√≥n muestra un buen desempe√±o del modelo:\n",
        "- 181 verdaderos negativos y 148 verdaderos positivos indican una buena capacidad para clasificar correctamente ambas clases.\n",
        "- Sin embargo, hay 28 falsos positivos y 33 falsos negativos, lo que sugiere que el modelo comete algunos errores, especialmente en la identificaci√≥n de la clase positiva.\n",
        "- Estos errores podr√≠an ser relevantes dependiendo del contexto del problema (por ejemplo, si detectar positivos es cr√≠tico)."
      ],
      "metadata": {
        "id": "cbcBvQDf_jVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curva ROC AUC."
      ],
      "metadata": {
        "id": "YAkrMHlM-DEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El ROC AUC (Receiver Operating Characteristic - Area Under Curve) es una m√©trica que mide la capacidad del modelo para distinguir entre clases (positiva y negativa), evaluando todas las combinaciones posibles de umbrales de clasificaci√≥n."
      ],
      "metadata": {
        "id": "K18ta-8I_yhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC: Es una curva que grafica la tasa de verdaderos positivos (TPR) contra la tasa de falsos positivos (FPR) a distintos umbrales.\n",
        "\n",
        "AUC (Area Under Curve): Es el √°rea bajo esa curva, y su valor va de 0 a 1:\n",
        "\n",
        "1.0 = modelo perfecto.\n",
        "\n",
        "0.5 = modelo sin capacidad de clasificaci√≥n (como adivinar).\n",
        "\n",
        "< 0.5 = peor que adivinar (clasifica al rev√©s)."
      ],
      "metadata": {
        "id": "RUs72JXbAGZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Curva ROC\n",
        "fpr, tpr, _ = roc_curve(y_test, model_log_reg.decision_function(X_test_tfidf))\n",
        "roc_auc = roc_auc_score(y_test, model_log_reg.decision_function(X_test_tfidf))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'√Årea bajo la curva ROC AUC = {roc_auc:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o6Iu7ehz9ZCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìà Interpretaci√≥n de tu resultado (AUC = 0.89):\n",
        "El valor 0.89 indica que el modelo tiene una alta capacidad para distinguir entre clases.\n",
        "\n",
        "En promedio, hay un 89% de probabilidad de que el modelo asigne un mayor score a una instancia positiva que a una negativa.\n",
        "\n",
        "Este resultado sugiere que el modelo est√° haciendo un buen trabajo, incluso si a√∫n hay algunos falsos positivos o falsos negativos."
      ],
      "metadata": {
        "id": "ENa983zfAKZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "M√©tricas de Predicci√≥n."
      ],
      "metadata": {
        "id": "Tzf7JNqq-FnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Accuracy:Para medir qu√© tan bien predice el modelo en datos nuevos (exactitud).\n",
        "Accuracy mide el porcentaje total de predicciones correctas sobre el total de casos.\n",
        "- Precision: Para medir el costo de un falso positivo es alto (por ejemplo, recomendar una pel√≠cula mala como buena).\n",
        "Precision mide qu√© proporci√≥n de las predicciones positivas hechas por el modelo son realmente positivas.\n",
        "- Recall: Para medir cu√°ntos de los casos positivos reales fueron capturados por el modelo.\n",
        "- f1 Score: Para medir el promedio arm√≥nico entre precisi√≥n y recall. Un buen balance si ambas cosas son importantes."
      ],
      "metadata": {
        "id": "EDNMuCVwAUwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. M√©tricas\n",
        "# Accuracy:Para medir qu√© tan bien predice el modelo en datos nuevos (exactitud).\n",
        "# Accuracy mide el porcentaje total de predicciones correctas sobre el total de casos.\n",
        "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
        "# Precision: Para medir el costo de un falso positivo es alto (por ejemplo, recomendar una pel√≠cula mala como buena).\n",
        "# Precision mide qu√© proporci√≥n de las predicciones positivas hechas por el modelo son realmente positivas.\n",
        "precision = precision_score(y_test, y_pred_log_reg)\n",
        "# Recall: Para medir cu√°ntos de los casos positivos reales fueron capturados por el modelo.\n",
        "recall = recall_score(y_test, y_pred_log_reg)\n",
        "#\n",
        "f1 = f1_score(y_test, y_pred_log_reg)\n",
        "\n",
        "print(\"M√©tricas de desempe√±o del modelo:\")\n",
        "print(f\"Accuracy : {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall   : {recall:.2f}\")\n",
        "print(f\"F1 Score : {f1:.2f}\")"
      ],
      "metadata": {
        "id": "yhq9A09B9Y2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados:\n",
        "\n",
        "- Accuracy = 0.82\n",
        "El 82% de todas las predicciones (positivas y negativas) fueron correctas. Es una medida general del rendimiento.\n",
        "Sin embargo, puede ser enga√±osa si las clases est√°n desbalanceadas.\n",
        "\n",
        "- Precision = 0.80\n",
        "De todas las predicciones positivas que hizo el modelo, el 80% fueron realmente positivas.\n",
        "Es importante si queremos minimizar falsos positivos (por ejemplo, evitar alarmas innecesarias).\n",
        "\n",
        "- Recall = 0.82\n",
        "El modelo identific√≥ correctamente el 82% de todos los casos realmente positivos.\n",
        "Es importante si queremos minimizar falsos negativos (por ejemplo, no dejar pasar casos positivos importantes).\n",
        "\n",
        "- F1 Score = 0.81\n",
        "Es el promedio arm√≥nico entre precision y recall. Resume el equilibrio entre ambos.\n",
        " Un F1 de 0.81 indica un buen balance entre identificar positivos y no equivocarse al predecirlos.\n"
      ],
      "metadata": {
        "id": "PpHJs1p1Avpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Validaci√≥n Cruzada.*"
      ],
      "metadata": {
        "id": "YhVd_UpcIthW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La validaci√≥n cruzada es una t√©cnica para evaluar la capacidad de generalizaci√≥n de un modelo. Consiste en:\n",
        "\n",
        "Dividir los datos en k partes (folds).\n",
        "\n",
        "Entrenar el modelo con k-1 partes y validar con la parte restante.\n",
        "\n",
        "Repetir esto k veces, cambiando el fold de validaci√≥n en cada iteraci√≥n.\n",
        "\n",
        "Calcular el promedio de las m√©tricas obtenidas en cada iteraci√≥n.\n",
        "\n",
        "Esto reduce el riesgo de que el modelo est√© sobreajustado (overfitting) a una √∫nica partici√≥n de los datos."
      ],
      "metadata": {
        "id": "sB0HBzUiBfUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline que junta vectorizador y modelo\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=5000),\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "# Validaci√≥n cruzada con 5 particiones (k-fold = 5)\n",
        "scores = cross_val_score(pipeline, df['Comentario'], df['Valor'], cv=5, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(f\"Precisi√≥n media con validaci√≥n cruzada: {scores.mean():.3f}\")\n",
        "print(f\"Desviaci√≥n est√°ndar: {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "I1TpkwSyI8OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados de la validaci√≥n cruzada:\n",
        "\n",
        "La precisi√≥n media del modelo es 0.807, lo que indica que, en promedio, el modelo acierta con un 80.7% de efectividad\n",
        "en los distintos subconjuntos del conjunto de datos evaluados.\n",
        "\n",
        "La desviaci√≥n est√°ndar es 0.018, lo que significa que el desempe√±o del modelo es bastante consistente entre los diferentes folds.\n",
        "Es decir, no hay una gran variaci√≥n en la precisi√≥n dependiendo del conjunto de entrenamiento/validaci√≥n utilizado.\n",
        "Estos resultados sugieren que el modelo tiene un buen rendimiento general y una buena capacidad de generalizaci√≥n."
      ],
      "metadata": {
        "id": "P1LeKo0ABsZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizaci√≥n de palabras asociadas a rese√±as positivas y negativas."
      ],
      "metadata": {
        "id": "voZXIBS9QDz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta visualizaci√≥n permite identificar las palabras m√°s frecuentes o relevantes en cada grupo de rese√±as, separando aquellas asociadas con opiniones positivas de las relacionadas con opiniones negativas.\n",
        "\n",
        "Al analizar estas palabras clave, podemos entender mejor qu√© aspectos del producto o servicio generan satisfacci√≥n o insatisfacci√≥n en los usuarios.\n",
        "\n",
        "Este tipo de an√°lisis ayuda a extraer insights cualitativos que complementan las m√©tricas cuantitativas, y es muy √∫til para mejorar la experiencia del cliente y orientar acciones espec√≠ficas de mejora."
      ],
      "metadata": {
        "id": "V8xiZv-rCDoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos las palabras del vocabulario\n",
        "palabras = tfidfvectorizer.get_feature_names_out()\n",
        "\n",
        "# Coeficientes del modelo (uno por palabra)\n",
        "coeficientes = model_log_reg.coef_[0]\n",
        "\n",
        "# Creamos un DataFrame para visualizarlo\n",
        "df_coef = pd.DataFrame({'palabra': palabras, 'coeficiente': coeficientes})\n",
        "\n",
        "# Ordenamos por importancia\n",
        "df_coef = df_coef.sort_values(by='coeficiente', ascending=False)\n",
        "\n",
        "# En la primera columna veremos el n√∫mero \"√≠ndice\" de cada palabra seg√∫n el √≥rden en que fueron procesadas en el modelo.\n",
        "\n",
        "# Mostramos las 10 palabras m√°s asociadas a valoraci√≥n positiva y negativa\n",
        "print(\"üîº Palabras m√°s asociadas a rese√±as positivas:\")\n",
        "print(df_coef.head(10))\n",
        "\n",
        "print(\"\\nüîΩ Palabras m√°s asociadas a rese√±as negativas:\")\n",
        "print(df_coef.tail(10))"
      ],
      "metadata": {
        "id": "2bJEOJTHQKb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las palabras con coeficientes positivos m√°s altos, como \"gran\", \"buen\", \"excelente\", \"funciona\" y \"incre√≠ble\", est√°n fuertemente asociadas con rese√±as positivas, reflejando satisfacci√≥n, calidad y buen desempe√±o del producto o servicio.\n",
        "\n",
        "En contraste, las palabras con coeficientes negativos m√°s fuertes, como \"no\", \"mala\", \"decepcionado\", \"horrible\" y \"terrible\", se asocian claramente con rese√±as negativas, indicando insatisfacci√≥n, problemas y decepci√≥n por parte de los usuarios.\n",
        "\n",
        "Esto muestra que el modelo ha identificado correctamente los t√©rminos que expresan opiniones positivas y negativas, lo que facilita la interpretaci√≥n y el an√°lisis cualitativo del sentimiento en los textos."
      ],
      "metadata": {
        "id": "NoIqfm9UCbRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficar las 10 palabras m√°s positivas y m√°s negativas"
      ],
      "metadata": {
        "id": "6inidvU-R88J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colores pastel suaves (m√°s apagados)\n",
        "color_positivas = '#388e3c'  # verde claro apagado\n",
        "color_negativas = '#e65100'  # rojo claro apagado\n",
        "\n",
        "# Top 10 positivas y negativas\n",
        "top_positivas = df_coef.head(10)\n",
        "top_negativas = df_coef.tail(10).sort_values(by='coeficiente')\n",
        "\n",
        "# Crear la figura y los ejes\n",
        "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Gr√°fico de palabras positivas\n",
        "bars1 = ax[0].barh(top_positivas['palabra'], top_positivas['coeficiente'], color=color_positivas)\n",
        "ax[0].set_title('üîº Palabras asociadas a rese√±as positivas', fontsize=14)\n",
        "ax[0].invert_yaxis()\n",
        "ax[0].set_xlabel('Coeficiente', fontsize=12)\n",
        "\n",
        "# Agregar valores al final de las barras (positivas)\n",
        "for bar in bars1:\n",
        "    width = bar.get_width()\n",
        "    ax[0].text(width + 0.01, bar.get_y() + bar.get_height() / 2,\n",
        "               f'{width:.2f}', va='center', fontsize=10)\n",
        "\n",
        "# Gr√°fico de palabras negativas\n",
        "bars2 = ax[1].barh(top_negativas['palabra'], top_negativas['coeficiente'], color=color_negativas)\n",
        "ax[1].set_title('üîΩ Palabras asociadas a rese√±as negativas', fontsize=14)\n",
        "ax[1].invert_yaxis()\n",
        "ax[1].set_xlabel('Coeficiente', fontsize=12)\n",
        "\n",
        "# Agregar valores al final de las barras (negativas)\n",
        "for bar in bars2:\n",
        "    width = bar.get_width()\n",
        "    ax[1].text(width - 0.01, bar.get_y() + bar.get_height() / 2,\n",
        "               f'{width:.2f}', va='center', ha='right', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VnNJCbVbRLMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar bigramas y trigramas\n",
        "# Cambiar 'ngrama' a 'palabra' para acceder a la columna correcta\n",
        "df_bi_tri = df_coef[df_coef['palabra'].str.count(' ') >= 2]\n",
        "\n",
        "top_pos_bi_tri = df_bi_tri.sort_values('coeficiente', ascending=False).head(10)\n",
        "top_neg_bi_tri = df_bi_tri.sort_values('coeficiente', ascending=True).head(10)\n",
        "\n",
        "color_positivas = '#388e3c'  # verde oscuro\n",
        "color_negativas = '#e65100'  # naranja oscuro\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16,6))\n",
        "\n",
        "axes[0].barh(top_pos_bi_tri['palabra'], top_pos_bi_tri['coeficiente'], color=color_positivas) # Cambiar 'ngrama' a 'palabra'\n",
        "axes[0].invert_yaxis()\n",
        "axes[0].set_title('üîº Bigrams y Trigrams positivos')\n",
        "axes[0].set_xlabel('Coeficiente')\n",
        "\n",
        "axes[1].barh(top_neg_bi_tri['palabra'], top_neg_bi_tri['coeficiente'], color=color_negativas) # Cambiar 'ngrama' a 'palabra'\n",
        "axes[1].invert_yaxis()\n",
        "axes[1].set_title('üîΩ Bigrams y Trigrams negativos')\n",
        "axes[1].set_xlabel('Coeficiente')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VgoYFK0eTcBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† ¬øQu√© muestran los gr√°ficos?\n",
        "Las palabras con coeficientes positivos son las que m√°s contribuyen a que el modelo prediga una rese√±a positiva.\n",
        "\n",
        "Las palabras con coeficientes negativos son las que m√°s empujan al modelo hacia una predicci√≥n negativa."
      ],
      "metadata": {
        "id": "11CjMM0lR28T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prueba del modelo."
      ],
      "metadata": {
        "id": "bbw6-1oWJYA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se genera un c√≥digo para probar distintas frases con comentarios genericos con el motivo de evaluar la funcionalidad del modelo de predicci√≥n."
      ],
      "metadata": {
        "id": "E7ssFQe3D2jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nueva_rese√±a = \"no lo recominedo\"  # Reemplaza con la rese√±a que deseas probar\n",
        "nueva_rese√±a_tfidf = tfidfvectorizer.transform([nueva_rese√±a])\n",
        "prediccion = model_log_reg.predict(nueva_rese√±a_tfidf)\n",
        "# Obtener la probabilidad de la predicci√≥n\n",
        "probabilidadpositiva = model_log_reg.predict_proba(nueva_rese√±a_tfidf)\n",
        "\n",
        "# Obtener la probabilidad en la clase predicha (0 o 1)\n",
        "probabilidad = probabilidadpositiva[0][1]  # Probabilidad de la clase \"positivo\"\n",
        "\n",
        "print(f\"Se predice que la cr√≠tica es de caracter {prediccion[0]}\")\n",
        "print(f\" con una probabilidad de que sea positiva de {probabilidad:.2f}\")"
      ],
      "metadata": {
        "id": "W8rk_rn_JdGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando Bag of Words."
      ],
      "metadata": {
        "id": "6nA1NdjV-tYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BoW convierte un conjunto de documentos en una matriz de ocurrencias de palabras. A diferencia de TF-IDF, que pondera las palabras seg√∫n su frecuencia e importancia en relaci√≥n con todo el corpus, BoW solo cuenta cu√°ntas veces aparece una palabra en un documento sin considerar la frecuencia global de la palabra."
      ],
      "metadata": {
        "id": "4N3SqoNl-9SG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ajuste de datos de entrenamiento para BoW."
      ],
      "metadata": {
        "id": "9O22cegICxIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciamos el vectorizador BoW\n",
        "vectorizer_bow = CountVectorizer()\n",
        "\n",
        "# Aplicamos el vectorizador a los comentarios lematizados (ahora en formato string)\n",
        "vector_bow = vectorizer_bow.fit_transform(df['Comentarios_sin_StopWords_str'])\n",
        "\n",
        "# Convertimos la matriz de caracter√≠sticas en un DataFrame para visualizar\n",
        "bow_df = pd.DataFrame(vector_bow.toarray(), columns=vectorizer_bow.get_feature_names_out())\n",
        "\n",
        "# Obtener los nombres de las caracter√≠sticas (palabras)\n",
        "features_bow = vectorizer_bow.get_feature_names_out()\n",
        "\n",
        "\n",
        "# Crear un DataFrame con las frecuencias de las palabras\n",
        "df_bow = pd.DataFrame(vector_bow.toarray(), columns=features_bow)"
      ],
      "metadata": {
        "id": "puoPyVHMDFOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar y transformar los datos de entrenamiento\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
        "# Transformar los datos de prueba\n",
        "X_test_bow  = X_test_bow  = vectorizer_bow.transform(X_test)"
      ],
      "metadata": {
        "id": "KuBThnFkC0eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generaci√≥n y prueba del Modelo con BoW."
      ],
      "metadata": {
        "id": "U-LmgSjwHBdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un modelo de regresi√≥n log√≠stica\n",
        "# Abajo ten√©s un c√≥digo con los par√°metros expresados de forma que puedas ir modificandolos\n",
        "model_log_reg_Bow = LogisticRegression() #Instanciamos el modelo\n",
        "\n",
        "# Entrenar el modelo\n",
        "model_log_reg_Bow.fit(X_train_bow, y_train) # Fiteamos, es decir, el modelo aprende a partir de los datos de entrenamiento\n",
        "\n",
        "# Hacer predicciones en el conjunto de prueba\n",
        "y_pred_log_reg_Bow = model_log_reg_Bow.predict(X_test_bow) # Predecir"
      ],
      "metadata": {
        "id": "qGBcMOnvHAle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluaci√≥n del Modelo.\n"
      ],
      "metadata": {
        "id": "PSo23e2IHX2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriz de Confusi√≥n."
      ],
      "metadata": {
        "id": "LxPQYjq3HhL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Matriz de confusi√≥n\n",
        "\n",
        "# La Matriz de Confusi√≥n es √∫til para Muestra los aciertos y errores del modelo organizados por clase.\n",
        "\n",
        "cm1 = confusion_matrix(y_test, y_pred_log_reg_Bow)\n",
        "labels = ['Negativo', 'Positivo']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicci√≥n')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusi√≥nc con BoW')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E9PBCupjHi8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curva ROC AUC."
      ],
      "metadata": {
        "id": "tlGSMfUAH1D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Curva ROC\n",
        "# ROC AUC SCORE eval√∫a qu√© tan bien el modelo separa las clases.\n",
        "fpr1, tpr1, _ = roc_curve(y_test, model_log_reg_Bow.decision_function(X_test_bow))\n",
        "roc_auc1 = roc_auc_score(y_test, model_log_reg_Bow.decision_function(X_test_bow))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr1, tpr1, color='darkorange', lw=2, label=f'√Årea bajo la curva ROC AUC = {roc_auc1:.2f}')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HONvbjo4HzuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M√©tricas de Predicci√≥n."
      ],
      "metadata": {
        "id": "vW0kWKhaIHmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. M√©tricas\n",
        "# Accuracy:Para medir qu√© tan bien predice el modelo en datos nuevos (exactitud).\n",
        "# Accuracy mide el porcentaje total de predicciones correctas sobre el total de casos.\n",
        "accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
        "# Precision: Para medir el costo de un falso positivo es alto (por ejemplo, recomendar una pel√≠cula mala como buena).\n",
        "# Precision mide qu√© proporci√≥n de las predicciones positivas hechas por el modelo son realmente positivas.\n",
        "precision = precision_score(y_test, y_pred_log_reg)\n",
        "# Recall: Para medir cu√°ntos de los casos positivos reales fueron capturados por el modelo.\n",
        "recall = recall_score(y_test, y_pred_log_reg)\n",
        "# f1 Score: Para medir el promedio arm√≥nico entre precisi√≥n y recall. Un buen balance si ambas cosas son importantes.\n",
        "f1 = f1_score(y_test, y_pred_log_reg)\n",
        "\n",
        "print(\"M√©tricas de desempe√±o del modelo:\")\n",
        "print(f\"Accuracy : {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall   : {recall:.2f}\")\n",
        "print(f\"F1 Score : {f1:.2f}\")"
      ],
      "metadata": {
        "id": "I2xeBzIoIL4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validaci√≥n Cruzada con BoW."
      ],
      "metadata": {
        "id": "NFXHSA1wO2U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline con Bag of Words y Regresi√≥n Log√≠stica\n",
        "pipeline1 = make_pipeline(\n",
        "    CountVectorizer(max_features=5000),  # Bag of Words\n",
        "    LogisticRegression()\n",
        ")\n",
        "\n",
        "# Validaci√≥n cruzada con 5 particiones\n",
        "scores = cross_val_score(pipeline1, df['Comentario'], df['Valor'], cv=5, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(f\"Precisi√≥n media con validaci√≥n cruzada (BoW): {scores.mean():.3f}\")\n",
        "print(f\"Desviaci√≥n est√°ndar: {scores.std():.3f}\")"
      ],
      "metadata": {
        "id": "vjenYlA_O4eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neuronales."
      ],
      "metadata": {
        "id": "ELvckxoswXK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prueba de Modelo con Keras."
      ],
      "metadata": {
        "id": "8XANfxe7IFA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizar los textos\n",
        "vectorizer_Neuro = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n",
        "X = vectorizer_Neuro.fit_transform(df['Comentarios_sin_StopWords_str']).toarray()"
      ],
      "metadata": {
        "id": "wLwCMh8r2OFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable objetivo\n",
        "y = df['Valor'].values  # Asegurate que sea 0 y 1"
      ],
      "metadata": {
        "id": "L5IRUcaa2oV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir en train y test (estratificado)\n",
        "X_train1, X_val, y_train1, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "Bw9CGsoF2tIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train1.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))  # 1 neurona y activaci√≥n sigmoid para binario\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',   # funci√≥n para binaria\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xa26Z1Wq0vAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos el resumen del modelo: esto nos dar√° detalles sobre cada capa y el n√∫mero de par√°metros entrenables en el modelo.\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IHjJPGEN3Z0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Use X_train1 and y_train1 which were specifically prepared for the neural network\n",
        "history = model.fit(X_train1, y_train1,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=100,\n",
        "                    batch_size=10,\n",
        "                    callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "ldJslQYk02Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
        "\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "29EyX-w_3KhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä Gr√°fico de Accuracy y Loss por √âpoca"
      ],
      "metadata": {
        "id": "Hc8eZPsB3fLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Entrenamiento', color='#4caf50')\n",
        "plt.plot(history.history['val_accuracy'], label='Validaci√≥n', color='#2196f3')\n",
        "plt.title('Precisi√≥n (Accuracy) por √âpoca')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('Precisi√≥n')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Entrenamiento', color='#f57c00')\n",
        "plt.plot(history.history['val_loss'], label='Validaci√≥n', color='#e53935')\n",
        "plt.title('P√©rdida (Loss) por √âpoca')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('P√©rdida')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "reR7qkjk3fpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train1, y_train1, verbose=False)\n",
        "print(\"Precisi√≥n Entrenamiento: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_val, y_val, verbose=False)\n",
        "print(\"Precisi√≥n Prueba:  {:.4f}\".format(accuracy))\n",
        ""
      ],
      "metadata": {
        "id": "zLicGea133U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluaci√≥n del modelo."
      ],
      "metadata": {
        "id": "x7duPNWG31EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**El modelo tiene overfitting**\n",
        "\n",
        "Si hay sobreajuste (overfitting), el modelo aprende demasiado bien los datos de entrenamiento, pero falla al generalizar en los datos nuevos (de validaci√≥n o test)."
      ],
      "metadata": {
        "id": "LhJgDdfOuPQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìà ¬øQu√© es accuracy?\n",
        "Accuracy (precisi√≥n) mide el porcentaje de predicciones correctas que hace tu modelo.\n",
        "\n",
        "Se suele graficar en funci√≥n de las √©pocas (cada ciclo completo de entrenamiento con todos los datos).\n",
        "\n",
        "‚úÖ Interpretaci√≥n:\n",
        "Si la accuracy de entrenamiento y validaci√≥n suben juntas, el modelo est√° aprendiendo bien.\n",
        "\n",
        "Si la accuracy de entrenamiento sube pero la de validaci√≥n se estanca o baja, puede estar sobreajustando (overfitting)."
      ],
      "metadata": {
        "id": "25abtumWq56q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìâ ¬øQu√© es loss?\n",
        "Loss es una medida del error que comete el modelo (por ejemplo, la entrop√≠a cruzada en clasificaci√≥n).\n",
        "\n",
        "El objetivo es minimizar la p√©rdida durante el entrenamiento.\n",
        "\n",
        "‚úÖ Interpretaci√≥n:\n",
        "Una loss que disminuye tanto en entrenamiento como validaci√≥n = buen aprendizaje.\n",
        "\n",
        "Si loss en validaci√≥n sube mientras la de entrenamiento baja = probable sobreajuste."
      ],
      "metadata": {
        "id": "xR8OJV-trDWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Seleccionar una rese√±a real del DataFrame\n",
        "indice = 1000  # Cambi√° este n√∫mero si quer√©s ver otra rese√±a\n",
        "\n",
        "oracion_real = df['Comentario'].iloc[indice]\n",
        "valoracion_real = df['Valor'].iloc[indice]\n",
        "\n",
        "# --- CAMBIO AQU√ç: Usar el mismo TF-IDF Vectorizer usado para entrenar la Red Neuronal ---\n",
        "# Asumiendo que 'vectorizer_Neuro' es el TfidfVectorizer utilizado para crear X_train1 y X_val\n",
        "# Es crucial que sea la *misma* instancia que fue fit_transformed en los datos de entrenamiento\n",
        "# Si no es la misma instancia, o si X_train1/X_val fueron creados con otro vectorizador, ajusta esto.\n",
        "# Basado en el c√≥digo anterior, parece que vectorizer_Neuro fue usado justo antes de dividir X, y.\n",
        "# Aseg√∫rate de que la celda donde se define vectorizer_Neuro se ejecuta antes que esta.\n",
        "nueva_rese√±a_vectorizada = vectorizer_Neuro.transform([oracion_real])\n",
        "\n",
        "# Paso 4: Predecir con el modelo\n",
        "# La predicci√≥n espera un tensor, y .transform() de TfidfVectorizer devuelve una matriz dispersa.\n",
        "# Necesitamos convertirla a un array denso si el modelo Sequential fue construido para aceptar entradas densas\n",
        "# como lo sugiere el error con Dense(input_shape=(X_train1.shape[1],)).\n",
        "# Asumiendo que X_train1 fue .toarray() despu√©s de TF-IDF.\n",
        "nueva_rese√±a_vectorizada_dense = nueva_rese√±a_vectorizada.toarray()\n",
        "\n",
        "prediccion = model.predict(nueva_rese√±a_vectorizada_dense)\n",
        "\n",
        "# Paso 5: Convertir la probabilidad a clase 0 o 1\n",
        "valoracion_predicha = 1 if prediccion[0][0] >= 0.5 else 0\n",
        "\n",
        "# Paso 6: Mostrar resultados\n",
        "print(f\"Rese√±a: {oracion_real}\")\n",
        "print(f\"Valoraci√≥n real: {valoracion_real}\")\n",
        "print(f\"Valoraci√≥n predicha: {valoracion_predicha}\")\n",
        "print(f\"Probabilidad predicha: {prediccion[0][0]:.4f}\")"
      ],
      "metadata": {
        "id": "DVJGqXxwgZtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testeamos con nuevas oraciones\n",
        "\n",
        "# Definir una nueva oraci√≥n para predecir.\n",
        "nueva_oracion = [\"si es fatal\"]\n",
        "\n",
        "nueva_secuencia_vectorizada = vectorizer_Neuro.transform(nueva_oracion)\n",
        "\n",
        "# Convertir a array denso si el modelo lo espera\n",
        "nueva_secuencia_vectorizada_dense = nueva_secuencia_vectorizada.toarray()\n",
        "\n",
        "\n",
        "# Usar el modelo para predecir la valoraci√≥n (0 o 1)\n",
        "\n",
        "prediccion = model.predict(nueva_secuencia_vectorizada_dense)\n",
        "\n",
        "print(f\"Predicci√≥n: {prediccion[0][0]}\")\n",
        "valoracion = 1 if prediccion[0][0] >= 0.5 else 0\n",
        "print(f\"Valoraci√≥n predicha: {valoracion}\")"
      ],
      "metadata": {
        "id": "vGXWFPv9_Rnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X ahora contiene un array de secuencias num√©ricas (en formato tensor o matriz), en las que cada n√∫mero representa un √≠ndice de palabra del vocabulario.\n",
        "# Estas secuencias est√°n ajustadas para tener la misma longitud (max_len=100), con las m√°s largas recortadas y las m√°s cortas rellenadas con ceros.\n",
        "# Visualizamos el tipo de dato que es X\n",
        "print(type(X))\n",
        "\n",
        "print(X)"
      ],
      "metadata": {
        "id": "n5IpwpRgdI9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üì¶ Tuning con Keras Tuner para clasificaci√≥n de sentimientos"
      ],
      "metadata": {
        "id": "cKUD3NJddNwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprovechando X_train1, X_val, y_train1, y_val  utilizadas en la primer pureba con Keras, utilizamos las mismas variables paa buscar los mejores hiperpar√°metros."
      ],
      "metadata": {
        "id": "Q89mG7ewsdaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. PADDEAR"
      ],
      "metadata": {
        "id": "OEUrdoqruYkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Los modelos de tf.keras esperan que todas las secuencias de entrada tengan la misma longitud\n",
        "#para poder agruparlas en una matriz (tensor) y procesarlas por lotes.\n",
        "\n",
        "# Define the maximum length for padding sequences\n",
        "max_len = 1000\n",
        "X_train_pad = pad_sequences(X_train1, maxlen=max_len)\n",
        "X_val_pad = pad_sequences(X_val, maxlen=max_len)"
      ],
      "metadata": {
        "id": "_aklVcYtHMYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üéØ 2. Definir funci√≥n para el modelo a tunear\n"
      ],
      "metadata": {
        "id": "WTLpPFuNHUAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Embedding(\n",
        "        input_dim=max_words + 1,\n",
        "        output_dim=hp.Choice(\"embedding_dim\", [32, 64, 128]),\n",
        "        input_length=max_len\n",
        "    ))\n",
        "\n",
        "    model.add(Bidirectional(SimpleRNN(\n",
        "        units=hp.Int(\"rnn_units\", min_value=16, max_value=64, step=16)\n",
        "    )))\n",
        "\n",
        "    model.add(Dropout(hp.Choice(\"dropout_rate\", [0.2, 0.3, 0.5])))\n",
        "\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "6Yjso00AHZCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üîç 3. Inicializar Keras Tuner\n",
        "\n"
      ],
      "metadata": {
        "id": "CurZB9ejHZzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el tama√±o del vocabulario basado en el vectorizador TF-IDF\n",
        "# utilizado anteriormente en la secci√≥n de Redes Neuronales.\n",
        "# 'vectorizer_Neuro' fue fit_transform en 'df['Comentarios_sin_StopWords_str']'\n",
        "max_words = len(vectorizer_Neuro.vocabulary_)\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory=\"keras_tuner_dir\",\n",
        "    project_name=\"sentiment_rnn_tuning\"\n",
        ")"
      ],
      "metadata": {
        "id": "zeHDY2D8Hdf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üöÄ 4. Ejecutar b√∫squeda"
      ],
      "metadata": {
        "id": "eD5MOpZAHhHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train_pad, y_train1, epochs=5, validation_data=(X_val_pad, y_val))"
      ],
      "metadata": {
        "id": "bSsYH6_RHj5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üèÜ 5. Ver los mejores hiperpar√°metros"
      ],
      "metadata": {
        "id": "XlXgTUIzHmh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "print(\"üîß Mejores hiperpar√°metros encontrados:\")\n",
        "for param in best_hp.values:\n",
        "    print(f\"{param}: {best_hp.get(param)}\")"
      ],
      "metadata": {
        "id": "MPWIrQBcHpOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üìà 6. Reentrenar el mejor modelo con m√°s √©pocas"
      ],
      "metadata": {
        "id": "4RZZfcdxHs2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.hypermodel.build(best_hp)\n",
        "\n",
        "history = best_model.fit(\n",
        "    X_train_pad, y_train1,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "ZUHtZRX1Hv55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üìä Gr√°ficos de entrenamiento vs validaci√≥n"
      ],
      "metadata": {
        "id": "7WEHd4zuH4nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer m√©tricas del objeto history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "# Crear figura\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Entrenamiento')\n",
        "plt.plot(epochs_range, val_acc, label='Validaci√≥n')\n",
        "plt.title('Precisi√≥n (accuracy)')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Entrenamiento')\n",
        "plt.plot(epochs_range, val_loss, label='Validaci√≥n')\n",
        "plt.title('P√©rdida (loss)')\n",
        "plt.xlabel('√âpoca')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_EurnQzRH49Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusiones.**"
      ],
      "metadata": {
        "id": "2Tuqz1acz2js"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regresion lineal utiliizando TF-IFD\n",
        "\n",
        "üß† Interpretaci√≥n general:\n",
        "Tu modelo tiene un rendimiento s√≥lido y equilibrado, con buena capacidad tanto para detectar verdaderos positivos (recall) como para evitar errores en las predicciones positivas (precision). El F1 Score confirma este equilibrio.\n",
        "\n"
      ],
      "metadata": {
        "id": "97FfnuhaBI5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Futuras Lineas.**"
      ],
      "metadata": {
        "id": "-WS2s6UKz5WS"
      }
    }
  ]
}